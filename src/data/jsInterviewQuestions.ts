export type JSInterviewTopic =
  | 'core-fundamentals'
  | 'functions-objects'
  | 'async-patterns'
  | 'modern-js'

export interface JSInterviewQuestion {
  id: number
  title: string
  difficulty: 'easy' | 'medium' | 'hard'
  topic: JSInterviewTopic
  subtopic: string
  answer: string
  codeExample?: string
  followUp: string
  keyTakeaway: string
}

export interface JSTopicConfig {
  id: JSInterviewTopic
  label: string
  description: string
}

export const jsTopics: JSTopicConfig[] = [
  {
    id: 'core-fundamentals',
    label: 'Core Fundamentals',
    description: 'Variables, types, scope, hoisting, coercion, operators',
  },
  {
    id: 'functions-objects',
    label: 'Functions & Objects',
    description: 'Closures, this keyword, prototypes, classes, patterns',
  },
  {
    id: 'async-patterns',
    label: 'Async JavaScript',
    description: 'Event loop, promises, async/await, microtasks, concurrency',
  },
  {
    id: 'modern-js',
    label: 'Modern JS & Patterns',
    description: 'ES6+ features, modules, iterators, error handling, Proxy',
  },
]

export const jsTopicMap: Record<JSInterviewTopic, JSTopicConfig> =
  Object.fromEntries(jsTopics.map((t) => [t.id, t])) as Record<JSInterviewTopic, JSTopicConfig>

export const jsInterviewQuestions: JSInterviewQuestion[] = [
{
  id: 1,
  title: 'What is JavaScript and how does it differ from Java?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'basics',
  answer: 'JavaScript is a dynamic, interpreted, multi-paradigm programming language primarily used to add interactivity to web pages. Despite the similar name, JavaScript and Java are fundamentally different languages — Java is statically typed, class-based, and compiled to bytecode, while JavaScript is dynamically typed, prototype-based, and executed by a runtime engine (like V8). JavaScript runs in browsers and on servers (via Node.js), supports first-class functions, and uses an event-driven, single-threaded execution model with an event loop for concurrency.',
  codeExample: '// JavaScript — dynamic typing, first-class functions\nconst greet = (name) => `Hello, ${name}!`;\nconsole.log(greet("World")); // "Hello, World!"\nconsole.log(typeof greet);   // "function"\n\n// Variables can change type at runtime\nlet value = 42;\nvalue = "now a string";\nconsole.log(typeof value);   // "string"',
  followUp: 'What does it mean that JavaScript is single-threaded, and how does it handle asynchronous operations?',
  keyTakeaway: 'JavaScript is a dynamic, prototype-based language unrelated to Java, designed for event-driven programming in browsers and servers.',
},
{
  id: 2,
  title: 'What are the primitive data types in JavaScript?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: 'JavaScript has seven primitive data types: `string`, `number`, `bigint`, `boolean`, `undefined`, `null`, and `symbol`. Primitives are immutable — when you manipulate a string or number, you always get a new value rather than modifying the original. They are compared by value, not by reference, which means two primitives with the same value are always considered equal. Everything that is not a primitive (objects, arrays, functions) is an `object` type and is compared by reference.',
  codeExample: '// All 7 primitive types\nconst str = "hello";        // string\nconst num = 42;             // number\nconst big = 9007199254740993n; // bigint\nconst bool = true;          // boolean\nconst undef = undefined;    // undefined\nconst nul = null;           // null\nconst sym = Symbol("id");   // symbol\n\n// Primitives are compared by value\nconsole.log(42 === 42);     // true\n// Objects are compared by reference\nconsole.log({} === {});     // false',
  followUp: 'Why does `typeof null` return `"object"` instead of `"null"`?',
  keyTakeaway: 'JavaScript has seven immutable primitive types — string, number, bigint, boolean, undefined, null, and symbol.',
},
{
  id: 3,
  title: 'What is the difference between `var`, `let`, and `const`?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: '`var` is function-scoped and hoisted to the top of its function with its value initialized to `undefined`. `let` and `const` are block-scoped (limited to the nearest `{}` block) and are hoisted but not initialized, creating a Temporal Dead Zone until the declaration is reached. `const` requires an initial value and prevents reassignment of the binding, but it does not make objects immutable — you can still mutate properties of a `const` object. In modern JavaScript, `const` is preferred by default, with `let` used only when reassignment is needed, and `var` is generally avoided.',
  codeExample: 'function example() {\n  console.log(a); // undefined (var is hoisted)\n  // console.log(b); // ReferenceError (TDZ)\n  // console.log(c); // ReferenceError (TDZ)\n\n  var a = 1;\n  let b = 2;\n  const c = 3;\n\n  // b = 20;  // OK — let allows reassignment\n  // c = 30;  // TypeError — const prevents reassignment\n\n  const obj = { x: 1 };\n  obj.x = 2;  // OK — mutating property is allowed\n  // obj = {}; // TypeError — reassigning binding is not\n}',
  followUp: 'What happens if you declare a `var` variable inside a `for` loop — does it leak out of the loop?',
  keyTakeaway: '`var` is function-scoped and hoisted; `let` and `const` are block-scoped with a TDZ; `const` prevents reassignment but not mutation.',
},
{
  id: 4,
  title: 'What is hoisting in JavaScript?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'hoisting',
  answer: 'Hoisting is the behavior where variable and function declarations are moved to the top of their scope during the compilation phase, before the code executes. Function declarations are fully hoisted — both the name and the function body are available from the start of the scope. `var` declarations are hoisted but initialized to `undefined`, so accessing them before the assignment gives `undefined` rather than an error. `let` and `const` declarations are hoisted into the Temporal Dead Zone and throw a `ReferenceError` if accessed before their declaration line.',
  codeExample: '// Function declarations are fully hoisted\nconsole.log(add(2, 3)); // 5\nfunction add(a, b) {\n  return a + b;\n}\n\n// var is hoisted with value undefined\nconsole.log(x); // undefined\nvar x = 10;\n\n// Function expressions are NOT fully hoisted\n// console.log(subtract(5, 2)); // TypeError\nvar subtract = function(a, b) {\n  return a - b;\n};',
  followUp: 'Are `class` declarations hoisted, and if so, how do they behave differently from function declarations?',
  keyTakeaway: 'Hoisting moves declarations to the top of their scope — function declarations fully, `var` as undefined, `let`/`const` into the TDZ.',
},
{
  id: 5,
  title: 'What is the difference between `==` and `===`?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'equality',
  answer: 'The `==` operator (loose equality) compares values after performing type coercion, meaning it converts operands to a common type before comparing. The `===` operator (strict equality) compares both value and type without any conversion, so operands must be the same type and the same value to be equal. For example, `"5" == 5` is `true` because the string is coerced to a number, but `"5" === 5` is `false` because a string and number are different types. Best practice is to always use `===` to avoid subtle bugs caused by implicit type conversion.',
  codeExample: '// Loose equality (==) performs type coercion\nconsole.log("5" == 5);     // true — string coerced to number\nconsole.log(0 == false);   // true — false coerced to 0\nconsole.log(null == undefined); // true — special rule\nconsole.log("" == 0);      // true — "" coerced to 0\n\n// Strict equality (===) checks type AND value\nconsole.log("5" === 5);    // false — different types\nconsole.log(0 === false);  // false — number vs boolean\nconsole.log(null === undefined); // false\nconsole.log(1 === 1);      // true — same type and value',
  followUp: 'Can you explain the type coercion rules that `==` follows when comparing different types?',
  keyTakeaway: '`===` checks type and value with no conversion; `==` coerces types first, leading to surprising truthy comparisons.',
},
{
  id: 6,
  title: 'What is the `typeof` operator and what does it return?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: 'The `typeof` operator returns a string indicating the type of its operand. It returns `"string"`, `"number"`, `"bigint"`, `"boolean"`, `"undefined"`, `"symbol"`, `"function"`, or `"object"` for everything else. The most notorious quirk is that `typeof null` returns `"object"` due to a legacy bug from the original JavaScript implementation that was never fixed for backward compatibility. Also, `typeof` on an undeclared variable returns `"undefined"` rather than throwing, which can be useful for feature detection.',
  codeExample: 'console.log(typeof "hello");    // "string"\nconsole.log(typeof 42);         // "number"\nconsole.log(typeof true);       // "boolean"\nconsole.log(typeof undefined);  // "undefined"\nconsole.log(typeof Symbol());   // "symbol"\nconsole.log(typeof 10n);        // "bigint"\nconsole.log(typeof function(){}); // "function"\n\n// Quirks\nconsole.log(typeof null);       // "object" (legacy bug)\nconsole.log(typeof [1, 2]);     // "object" (arrays are objects)\nconsole.log(typeof {});         // "object"\nconsole.log(typeof undeclaredVar); // "undefined" (no error)',
  followUp: 'How would you reliably check if a value is an array, since `typeof` returns `"object"` for arrays?',
  keyTakeaway: '`typeof` returns a string representing the type, but beware that `null` returns `"object"` and arrays return `"object"`.',
},
{
  id: 7,
  title: 'What is the difference between `null` and `undefined`?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: '`undefined` means a variable has been declared but not assigned a value — it is the default value JavaScript gives to uninitialized variables, missing function parameters, and missing object properties. `null` is an intentional assignment that represents the deliberate absence of any value. Both are falsy and loosely equal to each other (`null == undefined` is `true`), but they are different types: `typeof undefined` returns `"undefined"` while `typeof null` returns `"object"`. The convention is to use `null` when you want to explicitly signal "no value" and let `undefined` mean "not yet assigned."',
  codeExample: 'let a;\nconsole.log(a);          // undefined — declared but not assigned\nconsole.log(typeof a);   // "undefined"\n\nlet b = null;\nconsole.log(b);          // null — intentionally empty\nconsole.log(typeof b);   // "object" (legacy bug)\n\n// Loose equality treats them as equal\nconsole.log(null == undefined);  // true\nconsole.log(null === undefined); // false\n\n// Common pattern: check for both\nfunction isNullish(val) {\n  return val == null; // catches both null and undefined\n}',
  followUp: 'When would you use `void 0` instead of `undefined`, and why might that be necessary?',
  keyTakeaway: '`undefined` means a value was never assigned; `null` is an explicit assignment meaning "no value" — both are falsy but different types.',
},
{
  id: 8,
  title: 'What are template literals and how do they differ from regular strings?',
  difficulty: 'easy',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: 'Template literals are string literals delimited by backticks (`` ` ``) instead of single or double quotes. They support three features that regular strings lack: embedded expressions via `${expression}` interpolation, multi-line strings without escape characters, and tagged templates that let you process the literal with a custom function. Interpolated expressions can be any valid JavaScript expression, including function calls, ternary operators, and arithmetic. Template literals make string building far more readable than traditional concatenation with the `+` operator.',
  codeExample: 'const name = "Alice";\nconst age = 30;\n\n// String interpolation\nconst greeting = `Hello, ${name}! You are ${age} years old.`;\n\n// Expressions inside interpolation\nconst msg = `Next year you will be ${age + 1}.`;\n\n// Multi-line strings (no \\n needed)\nconst html = `\n  <div>\n    <h1>${name}</h1>\n    <p>Age: ${age}</p>\n  </div>\n`;\n\n// Conditional logic inside template\nconst status = `User is ${age >= 18 ? "adult" : "minor"}.`;',
  followUp: 'What are tagged template literals, and can you give an example of when you would use one?',
  keyTakeaway: 'Template literals use backticks for string interpolation, multi-line support, and tagged processing — replacing clunky concatenation.',
},
{
  id: 9,
  title: 'Explain how JavaScript type coercion works with examples.',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'coercion',
  answer: 'Type coercion is the automatic conversion of values from one type to another during operations. JavaScript has two kinds: implicit coercion (triggered by operators and comparisons) and explicit coercion (using functions like `Number()`, `String()`, or `Boolean()`). The `+` operator is especially tricky — if either operand is a string, it concatenates; otherwise it adds numerically. Other arithmetic operators (`-`, `*`, `/`) always coerce to numbers. Comparison operators coerce both sides to numbers except when both are strings (which triggers lexicographic comparison). Understanding these rules prevents a major class of bugs in JavaScript.',
  codeExample: '// String + number = concatenation\nconsole.log("5" + 3);       // "53" (number coerced to string)\nconsole.log("5" - 3);       // 2   (string coerced to number)\n\n// Boolean coercion\nconsole.log(true + 1);      // 2   (true becomes 1)\nconsole.log(false + "");    // "false" (boolean to string)\n\n// Object coercion calls valueOf() then toString()\nconsole.log([] + []);       // "" (both become empty strings)\nconsole.log([] + {});       // "[object Object]"\nconsole.log({} + []);       // 0 (in some engines, {} is a block)\n\n// Explicit coercion\nconsole.log(Number("42"));  // 42\nconsole.log(String(42));    // "42"\nconsole.log(Boolean(0));    // false',
  followUp: 'What are the abstract operations `ToPrimitive`, `ToNumber`, and `ToString` that the spec defines for coercion?',
  keyTakeaway: 'Type coercion automatically converts types during operations — `+` concatenates with strings, while `-`, `*`, `/` coerce to numbers.',
},
{
  id: 10,
  title: 'What is the scope chain and how does variable lookup work?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'scope',
  answer: 'The scope chain is the ordered list of scopes that the JavaScript engine searches through when resolving a variable reference. When code references a variable, the engine first looks in the current local scope, then moves outward through each enclosing scope until it reaches the global scope. If the variable is not found in any scope, a `ReferenceError` is thrown. Each function creates a new scope, and inner functions have access to variables in all outer scopes through this chain — this is the foundation of closures. The scope chain is determined lexically (at write time), not at runtime.',
  codeExample: 'const global = "I am global";\n\nfunction outer() {\n  const outerVar = "I am outer";\n\n  function inner() {\n    const innerVar = "I am inner";\n    console.log(innerVar);  // Found in local scope\n    console.log(outerVar);  // Found in outer scope\n    console.log(global);    // Found in global scope\n    // console.log(missing); // ReferenceError\n  }\n\n  inner();\n}\n\nouter();\n// Scope chain for inner(): inner -> outer -> global',
  followUp: 'How does the scope chain relate to closures, and can you give an example of a closure that captures a variable?',
  keyTakeaway: 'The scope chain is a lexical hierarchy — variable lookup starts in the current scope and walks outward until the variable is found or global scope is exhausted.',
},
{
  id: 11,
  title: 'What is the Temporal Dead Zone (TDZ)?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'hoisting',
  answer: 'The Temporal Dead Zone is the period between entering a scope and the point where a `let` or `const` variable is declared. During this window, the variable exists in the scope (it is hoisted) but is not initialized, so any attempt to access it throws a `ReferenceError`. The TDZ exists to catch bugs where code accidentally uses a variable before it is ready. Unlike `var` which is initialized to `undefined` during hoisting, `let` and `const` remain in an uninitialized state until the engine executes the actual declaration statement. The TDZ also applies to `class` declarations and default parameter values.',
  codeExample: '// TDZ starts at the beginning of the block\n{\n  // console.log(x); // ReferenceError: Cannot access \'x\' before initialization\n  // TDZ for \'x\' is active here\n\n  let x = 42;       // TDZ ends, x is now initialized\n  console.log(x);   // 42\n}\n\n// TDZ in function parameters\nfunction broken(a = b, b = 1) {\n  // ReferenceError: b is in TDZ when a\'s default is evaluated\n}\n// broken();\n\nfunction working(a = 1, b = a) {\n  console.log(a, b); // 1 1\n}\nworking();',
  followUp: 'Does `typeof` also throw in the TDZ, or does it safely return `"undefined"` like it does for undeclared variables?',
  keyTakeaway: 'The TDZ is the gap between scope entry and declaration where `let`/`const` variables exist but are uninitialized and throw on access.',
},
{
  id: 12,
  title: 'How do truthy and falsy values work in JavaScript?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'coercion',
  answer: 'In boolean contexts (like `if` conditions, logical operators, and ternaries), JavaScript coerces any value to either `true` or `false`. There are exactly eight falsy values: `false`, `0`, `-0`, `0n` (BigInt zero), `""` (empty string), `null`, `undefined`, and `NaN`. Every other value is truthy, including empty objects `{}`, empty arrays `[]`, the string `"0"`, and the string `"false"`. This behavior is used extensively in conditional logic and short-circuit patterns, but it can cause subtle bugs — for example, `0` and `""` are legitimate values that evaluate as falsy.',
  codeExample: '// All 8 falsy values\nconsole.log(Boolean(false));     // false\nconsole.log(Boolean(0));         // false\nconsole.log(Boolean(-0));        // false\nconsole.log(Boolean(0n));        // false\nconsole.log(Boolean(""));        // false\nconsole.log(Boolean(null));      // false\nconsole.log(Boolean(undefined)); // false\nconsole.log(Boolean(NaN));       // false\n\n// Surprising truthy values\nconsole.log(Boolean([]));        // true (empty array)\nconsole.log(Boolean({}));        // true (empty object)\nconsole.log(Boolean("0"));       // true (non-empty string)\nconsole.log(Boolean("false"));   // true (non-empty string)\n\n// Practical pitfall\nconst count = 0;\nif (count) { /* skipped — 0 is falsy! */ }\nif (count !== undefined) { /* correct check */ }',
  followUp: 'How does the `!!` double negation pattern work, and when would you use it over `Boolean()`?',
  keyTakeaway: 'JavaScript has exactly 8 falsy values — everything else is truthy, including empty arrays, empty objects, and the string `"0"`.',
},
{
  id: 13,
  title: 'What is the difference between `for...in` and `for...of`?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'operators',
  answer: '`for...in` iterates over the enumerable property keys (strings) of an object, including inherited properties from the prototype chain. `for...of` iterates over the values of any iterable object (arrays, strings, Maps, Sets, generators) by consuming its `Symbol.iterator` protocol. Using `for...in` on arrays is generally discouraged because it iterates over index strings (not numbers), includes non-index enumerable properties, and does not guarantee order. For objects, `for...in` is appropriate; for arrays and other iterables, `for...of` is the correct choice.',
  codeExample: 'const arr = ["a", "b", "c"];\narr.customProp = "oops";\n\n// for...in: iterates over keys (including inherited/custom)\nfor (const key in arr) {\n  console.log(key); // "0", "1", "2", "customProp"\n}\n\n// for...of: iterates over values (iterable protocol)\nfor (const val of arr) {\n  console.log(val); // "a", "b", "c"\n}\n\n// for...in on objects\nconst obj = { x: 1, y: 2 };\nfor (const key in obj) {\n  console.log(key, obj[key]); // "x" 1, "y" 2\n}\n\n// for...of on strings\nfor (const char of "hello") {\n  console.log(char); // "h", "e", "l", "l", "o"\n}',
  followUp: 'How would you iterate over an object\'s own properties only, excluding inherited ones?',
  keyTakeaway: '`for...in` iterates over enumerable property keys on objects; `for...of` iterates over values of iterables like arrays and strings.',
},
{
  id: 14,
  title: 'How does short-circuit evaluation work with `&&` and `||`?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'operators',
  answer: 'Short-circuit evaluation means logical operators stop evaluating as soon as the result is determined and return the value that decided the outcome (not necessarily a boolean). The `&&` operator returns the first falsy value it encounters or the last value if all are truthy. The `||` operator returns the first truthy value it encounters or the last value if all are falsy. This behavior is commonly used for conditional execution (`condition && doSomething()`), default values (`value || fallback`), and guard clauses. The key insight is that these operators return one of their operands, not `true` or `false`.',
  codeExample: '// && returns first falsy or last value\nconsole.log("hello" && 42);     // 42 (both truthy, returns last)\nconsole.log("" && 42);          // "" (first is falsy, returns it)\nconsole.log(1 && 2 && 3);       // 3\nconsole.log(1 && 0 && 3);       // 0\n\n// || returns first truthy or last value\nconsole.log("" || "fallback");  // "fallback"\nconsole.log("hello" || "nope"); // "hello"\nconsole.log(0 || "" || null);   // null (all falsy, returns last)\n\n// Practical patterns\nconst user = { name: "Alice" };\nconst displayName = user.name || "Anonymous";\n\n// Conditional execution\nconst isAdmin = true;\nisAdmin && console.log("Welcome, admin!");',
  followUp: 'Why might `||` be problematic for default values when `0` or `""` are valid, and what operator solves this?',
  keyTakeaway: '`&&` returns the first falsy operand or the last value; `||` returns the first truthy operand or the last value — neither necessarily returns a boolean.',
},
{
  id: 15,
  title: 'What are the nullish coalescing (`??`) and optional chaining (`?.`) operators?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'operators',
  answer: 'The nullish coalescing operator (`??`) returns its right-hand operand when the left-hand side is `null` or `undefined`, and returns the left-hand side otherwise. Unlike `||`, it does not treat `0`, `""`, or `false` as triggers for the fallback, making it safe for default values where those are legitimate. The optional chaining operator (`?.`) short-circuits and returns `undefined` if the value before it is `null` or `undefined`, preventing "Cannot read property of undefined" errors. Together, they provide safe property access and default value assignment without the falsy-value bugs that `||` introduces.',
  codeExample: '// ?? only triggers on null/undefined, not other falsy values\nconsole.log(0 ?? 42);         // 0 (0 is not nullish)\nconsole.log("" ?? "default"); // "" (empty string is not nullish)\nconsole.log(null ?? "fallback"); // "fallback"\nconsole.log(undefined ?? 10);    // 10\n\n// Compare with ||\nconsole.log(0 || 42);         // 42 (0 is falsy!)\nconsole.log("" || "default"); // "default" ("" is falsy!)\n\n// ?. prevents errors on null/undefined\nconst user = { address: { city: "NYC" } };\nconsole.log(user.address?.city);    // "NYC"\nconsole.log(user.profile?.avatar);  // undefined (no error)\nconsole.log(user.getRole?.());      // undefined (safe method call)\n\n// Combined pattern\nconst port = config?.server?.port ?? 3000;',
  followUp: 'Can you mix `??` with `&&` or `||` without parentheses, and what happens if you try?',
  keyTakeaway: '`??` provides defaults only for `null`/`undefined` (not all falsy values), and `?.` safely accesses nested properties without throwing.',
},
{
  id: 16,
  title: 'What is destructuring assignment and how does it work?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'destructuring',
  answer: 'Destructuring assignment is a syntax that unpacks values from arrays or properties from objects into distinct variables. Array destructuring uses position-based extraction with square brackets, while object destructuring uses key names with curly braces. Both support default values for missing/undefined properties, renaming (in objects), rest elements to collect remaining items, and nested destructuring for deeply structured data. Destructuring works in variable declarations, function parameters, and assignment expressions, making it one of the most versatile features introduced in ES6.',
  codeExample: '// Array destructuring (position-based)\nconst [first, second, ...rest] = [1, 2, 3, 4, 5];\nconsole.log(first, second, rest); // 1, 2, [3, 4, 5]\n\n// Skipping elements\nconst [, , third] = [1, 2, 3];\nconsole.log(third); // 3\n\n// Object destructuring (key-based)\nconst { name, age, role = "user" } = { name: "Alice", age: 30 };\nconsole.log(name, age, role); // "Alice", 30, "user"\n\n// Renaming + nested\nconst { address: { city: hometown } } = {\n  address: { city: "NYC" }\n};\nconsole.log(hometown); // "NYC"\n\n// In function parameters\nfunction greet({ name, greeting = "Hello" }) {\n  return `${greeting}, ${name}!`;\n}\nconsole.log(greet({ name: "Bob" })); // "Hello, Bob!"',
  followUp: 'How would you swap two variables using destructuring without a temporary variable?',
  keyTakeaway: 'Destructuring unpacks values from arrays by position and from objects by key, supporting defaults, renaming, rest, and nesting.',
},
{
  id: 17,
  title: 'What is the spread operator and how does it differ from the rest parameter?',
  difficulty: 'medium',
  topic: 'core-fundamentals',
  subtopic: 'destructuring',
  answer: 'The spread operator (`...`) expands an iterable (array, string, object) into individual elements in places where multiple values are expected, like function arguments, array literals, or object literals. The rest parameter uses the same `...` syntax but works in the opposite direction — it collects multiple elements into a single array in function parameters or destructuring patterns. Spread creates shallow copies, meaning nested objects still share references. The key distinction is context: spread appears in expressions where values are produced, while rest appears in patterns where values are captured.',
  codeExample: '// Spread: expanding into individual elements\nconst arr1 = [1, 2, 3];\nconst arr2 = [...arr1, 4, 5]; // [1, 2, 3, 4, 5]\n\nconst obj1 = { a: 1, b: 2 };\nconst obj2 = { ...obj1, c: 3 }; // { a: 1, b: 2, c: 3 }\n\n// Spread in function calls\nMath.max(...arr1); // 3\n\n// Rest: collecting into a single array\nfunction sum(...numbers) {\n  return numbers.reduce((a, b) => a + b, 0);\n}\nconsole.log(sum(1, 2, 3, 4)); // 10\n\n// Rest in destructuring\nconst [head, ...tail] = [1, 2, 3, 4];\nconsole.log(head); // 1\nconsole.log(tail); // [2, 3, 4]\n\n// Shallow copy warning\nconst nested = { data: { x: 1 } };\nconst copy = { ...nested };\ncopy.data.x = 99;\nconsole.log(nested.data.x); // 99 (shared reference!)',
  followUp: 'How does spread behave with object property conflicts — which value wins when the same key appears multiple times?',
  keyTakeaway: 'Spread expands iterables into individual elements; rest collects multiple elements into an array — same `...` syntax, opposite directions.',
},
{
  id: 18,
  title: 'How does JavaScript handle floating-point arithmetic and what are its pitfalls?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: 'JavaScript uses the IEEE 754 double-precision (64-bit) floating-point format for all numbers, which means some decimal fractions cannot be represented exactly in binary. The classic example is `0.1 + 0.2 === 0.30000000000000004` instead of `0.3`. This affects financial calculations and equality comparisons with decimal values. Safe integer range is `-(2^53 - 1)` to `2^53 - 1` (`Number.MIN_SAFE_INTEGER` to `Number.MAX_SAFE_INTEGER`); beyond that, integers lose precision. Workarounds include using `Number.EPSILON` for floating-point comparison, scaling to integers for arithmetic (e.g., cents instead of dollars), or using `BigInt` for exact large integer math.',
  codeExample: '// Floating-point precision issue\nconsole.log(0.1 + 0.2);         // 0.30000000000000004\nconsole.log(0.1 + 0.2 === 0.3); // false\n\n// Epsilon-based comparison\nfunction nearlyEqual(a, b) {\n  return Math.abs(a - b) < Number.EPSILON;\n}\nconsole.log(nearlyEqual(0.1 + 0.2, 0.3)); // true\n\n// Integer scaling for money\nconst priceInCents = 10 + 20; // 30 cents\nconsole.log(priceInCents / 100); // 0.3 (exact)\n\n// Safe integer limits\nconsole.log(Number.MAX_SAFE_INTEGER);     // 9007199254740991\nconsole.log(9007199254740992 === 9007199254740993); // true (!)\n\n// BigInt for large exact integers\nconsole.log(9007199254740992n === 9007199254740993n); // false',
  followUp: 'What is `Number.EPSILON`, and why is it not always sufficient for floating-point comparisons?',
  keyTakeaway: 'JavaScript uses IEEE 754 doubles so `0.1 + 0.2 !== 0.3` — use integer scaling for money and `BigInt` for large integers.',
},
{
  id: 19,
  title: 'Explain pass-by-value vs pass-by-reference in JavaScript.',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: 'JavaScript is always pass-by-value, but the value for objects is a reference (memory address). Primitives are copied entirely when passed to a function, so changes inside the function do not affect the original. Objects (including arrays and functions) pass a copy of the reference, meaning the function receives a pointer to the same object in memory — mutations to the object are visible outside the function, but reassigning the parameter to a new object does not affect the caller. This is sometimes called "pass-by-sharing" or "call-by-object-sharing" to distinguish it from true pass-by-reference (as in C++ references), where reassigning the parameter would change the caller\'s variable.',
  codeExample: '// Primitives: pass-by-value (copy of value)\nfunction changePrimitive(x) {\n  x = 100;\n}\nlet num = 42;\nchangePrimitive(num);\nconsole.log(num); // 42 (unchanged)\n\n// Objects: pass-by-value (copy of reference)\nfunction mutateObject(obj) {\n  obj.name = "changed"; // Mutates the original\n}\nconst person = { name: "Alice" };\nmutateObject(person);\nconsole.log(person.name); // "changed"\n\n// Reassignment does NOT affect the original\nfunction replaceObject(obj) {\n  obj = { name: "replaced" }; // New reference, no effect outside\n}\nconst user = { name: "Bob" };\nreplaceObject(user);\nconsole.log(user.name); // "Bob" (unchanged)',
  followUp: 'How would you write a function that can modify a primitive value accessible to the caller?',
  keyTakeaway: 'JavaScript passes primitive values as copies and object references as copies — mutation is shared, but reassignment is not.',
},
{
  id: 20,
  title: 'How does garbage collection work in JavaScript (mark-and-sweep)?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: 'JavaScript uses automatic garbage collection, primarily the mark-and-sweep algorithm. The garbage collector starts from root objects (global scope, current call stack, active closures) and traverses all reachable references, marking each object it can reach. Any object not marked is considered unreachable and its memory is reclaimed. Modern engines like V8 use generational garbage collection, dividing the heap into a "young generation" (frequently collected with Scavenge) and an "old generation" (less frequently collected with Mark-Compact). Common memory leak patterns include forgotten event listeners, closures capturing large scopes, detached DOM nodes, and accidental globals created by missing `var`/`let`/`const`.',
  codeExample: '// Object becomes eligible for GC when unreachable\nlet obj = { data: new Array(1000000) };\nobj = null; // Original object is now unreachable -> GC eligible\n\n// Closure retains reference, preventing GC\nfunction createLeak() {\n  const largeData = new Array(1000000);\n  return function() {\n    console.log(largeData.length); // largeData is retained\n  };\n}\nconst leak = createLeak(); // largeData stays in memory\n\n// Common leak: forgotten event listeners\nfunction setupHandler() {\n  const data = loadHugeDataset();\n  element.addEventListener("click", () => {\n    console.log(data); // data retained until listener removed\n  });\n}\n// Fix: element.removeEventListener(...) when done\n\n// WeakMap/WeakSet allow GC of keys\nconst cache = new WeakMap();\nlet key = { id: 1 };\ncache.set(key, "cached");\nkey = null; // entry in WeakMap can be garbage collected',
  followUp: 'What is the difference between `WeakMap` and `Map` in terms of garbage collection behavior?',
  keyTakeaway: 'JavaScript uses mark-and-sweep GC — objects reachable from roots survive; unreachable objects are freed automatically.',
},
{
  id: 21,
  title: 'What are Symbols and what are their use cases?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'types',
  answer: 'A `Symbol` is a primitive type that produces a unique, immutable identifier every time `Symbol()` is called. Even two Symbols with the same description are never equal. They are used to create non-enumerable, collision-free property keys on objects, preventing accidental overwrites by other code. JavaScript uses built-in "well-known" Symbols like `Symbol.iterator`, `Symbol.toPrimitive`, and `Symbol.hasInstance` to hook into language-level behaviors. `Symbol.for(key)` creates global Symbols that are shared across realms (iframes, workers) via a global registry, unlike regular Symbols which are always unique.',
  codeExample: '// Every Symbol is unique\nconst s1 = Symbol("id");\nconst s2 = Symbol("id");\nconsole.log(s1 === s2); // false\n\n// Symbol as a collision-free property key\nconst ID = Symbol("id");\nconst user = { name: "Alice", [ID]: 123 };\nconsole.log(user[ID]);         // 123\nconsole.log(Object.keys(user)); // ["name"] (Symbol is not enumerable)\n\n// Well-known Symbols: custom iterator\nconst range = {\n  start: 1,\n  end: 5,\n  [Symbol.iterator]() {\n    let current = this.start;\n    const end = this.end;\n    return {\n      next() {\n        return current <= end\n          ? { value: current++, done: false }\n          : { done: true };\n      }\n    };\n  }\n};\nconsole.log([...range]); // [1, 2, 3, 4, 5]\n\n// Global registry\nconst global1 = Symbol.for("app.id");\nconst global2 = Symbol.for("app.id");\nconsole.log(global1 === global2); // true',
  followUp: 'How would you use `Symbol.toPrimitive` to control how an object converts to a string or number?',
  keyTakeaway: 'Symbols are unique, immutable identifiers used for collision-free object keys and hooking into language behaviors via well-known Symbols.',
},
{
  id: 22,
  title: 'What is the difference between `Object.freeze()`, `Object.seal()`, and `Object.preventExtensions()`?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: '`Object.preventExtensions()` prevents new properties from being added to an object but allows existing properties to be modified or deleted. `Object.seal()` does the same plus prevents existing properties from being deleted — it marks all existing properties as non-configurable, but values can still be changed. `Object.freeze()` is the most restrictive — it seals the object and additionally makes all properties read-only, preventing any modifications. All three operations are shallow, meaning nested objects remain mutable. To deeply freeze an object, you must recursively call `Object.freeze()` on all nested objects.',
  codeExample: '// Object.preventExtensions — no new props, can modify/delete\nconst ext = { a: 1, b: 2 };\nObject.preventExtensions(ext);\next.a = 10;       // OK — modification allowed\ndelete ext.b;     // OK — deletion allowed\next.c = 3;        // Silently fails (or TypeError in strict mode)\n\n// Object.seal — no new props, no delete, can modify\nconst sealed = { a: 1, b: 2 };\nObject.seal(sealed);\nsealed.a = 10;    // OK — modification allowed\ndelete sealed.b;  // Fails — deletion prevented\nsealed.c = 3;     // Fails — no new properties\n\n// Object.freeze — fully immutable (shallow)\nconst frozen = { a: 1, nested: { x: 1 } };\nObject.freeze(frozen);\nfrozen.a = 10;        // Fails — modification prevented\nfrozen.nested.x = 99; // Works! — shallow freeze only\n\nconsole.log(Object.isFrozen(frozen));   // true\nconsole.log(Object.isSealed(frozen));   // true\nconsole.log(Object.isExtensible(frozen)); // false',
  followUp: 'How would you implement a deep freeze utility that makes an entire object tree immutable?',
  keyTakeaway: '`preventExtensions` blocks additions, `seal` also blocks deletions, `freeze` also blocks modifications — all are shallow.',
},
{
  id: 23,
  title: 'How does `Object.is()` differ from `===` and `==`?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'equality',
  answer: '`Object.is()` uses the SameValue algorithm, which behaves identically to `===` (strict equality) in most cases but fixes two edge cases where `===` produces counterintuitive results. First, `Object.is(NaN, NaN)` returns `true`, whereas `NaN === NaN` is `false`. Second, `Object.is(+0, -0)` returns `false`, whereas `+0 === -0` is `true`. These distinctions matter in algorithms that need to distinguish between positive and negative zero (like `Math.sign` analysis) or reliably detect `NaN` without `isNaN()`. React uses `Object.is()` internally for state comparison in `useState` and `useMemo` to determine if a re-render is needed.',
  codeExample: '// NaN comparison\nconsole.log(NaN === NaN);           // false\nconsole.log(Object.is(NaN, NaN));   // true\nconsole.log(isNaN(NaN));            // true (alternative)\n\n// +0 vs -0 comparison\nconsole.log(+0 === -0);             // true\nconsole.log(Object.is(+0, -0));     // false\n\n// All other cases behave like ===\nconsole.log(Object.is(1, 1));       // true\nconsole.log(Object.is("a", "a"));   // true\nconsole.log(Object.is(null, null)); // true\nconsole.log(Object.is(1, "1"));     // false (no coercion)\n\n// Polyfill shows the logic\nfunction sameValue(x, y) {\n  if (x === y) {\n    // Handle +0 vs -0\n    return x !== 0 || 1 / x === 1 / y;\n  }\n  // Handle NaN vs NaN\n  return x !== x && y !== y;\n}',
  followUp: 'Why does React use `Object.is()` instead of `===` for comparing state values?',
  keyTakeaway: '`Object.is()` is like `===` but treats `NaN === NaN` as `true` and `+0 === -0` as `false` — fixing two strict equality quirks.',
},
{
  id: 24,
  title: 'What are tagged template literals and how do they work?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: 'A tagged template literal is a function call where the function name is placed directly before a template literal, with no parentheses. The tag function receives the static string segments as a frozen array in its first parameter, and the interpolated expression values as subsequent parameters. The tag function can process, transform, or sanitize the strings and values in any way before returning a result (which does not have to be a string). The raw strings (with escape sequences unprocessed) are available via `strings.raw`. Real-world uses include CSS-in-JS libraries like styled-components, SQL injection prevention, internationalization, and GraphQL query building.',
  codeExample: '// Tag function receives strings array and values\nfunction highlight(strings, ...values) {\n  return strings.reduce((result, str, i) => {\n    const val = values[i] !== undefined ? `<b>${values[i]}</b>` : "";\n    return result + str + val;\n  }, "");\n}\n\nconst name = "Alice";\nconst age = 30;\nconsole.log(highlight`Name: ${name}, Age: ${age}`);\n// "Name: <b>Alice</b>, Age: <b>30</b>"\n\n// SQL injection prevention\nfunction sql(strings, ...values) {\n  const escaped = values.map(v =>\n    typeof v === "string" ? v.replace(/\'/g, "\\\'") : v\n  );\n  return strings.reduce((q, str, i) =>\n    q + str + (escaped[i] ?? ""), ""\n  );\n}\nconst userInput = "Robert\'; DROP TABLE users--";\nconst query = sql`SELECT * FROM users WHERE name = \'${userInput}\'`;\n\n// Raw strings (escape sequences preserved)\nfunction raw(strings) {\n  return strings.raw[0];\n}\nconsole.log(raw`Hello\\nWorld`); // "Hello\\nWorld" (not a newline)',
  followUp: 'How do CSS-in-JS libraries like styled-components use tagged template literals under the hood?',
  keyTakeaway: 'Tagged templates pass string segments and interpolated values to a function, enabling custom processing like sanitization and DSLs.',
},
{
  id: 25,
  title: 'What are WeakRef and FinalizationRegistry?',
  difficulty: 'hard',
  topic: 'core-fundamentals',
  subtopic: 'variables',
  answer: '`WeakRef` creates a weak reference to an object that does not prevent garbage collection — you can access the object via `deref()`, which returns the object if still alive or `undefined` if it has been collected. `FinalizationRegistry` lets you register a callback that fires after an object has been garbage collected, useful for cleaning up external resources like file handles or network connections. Both were introduced in ES2021 and are non-deterministic — you cannot predict exactly when GC will run, so you must never rely on them for critical application logic. Common use cases include building memory-sensitive caches, tracking object lifecycles for debugging, and releasing unmanaged resources.',
  codeExample: '// WeakRef — holds a weak reference to an object\nlet target = { data: "important" };\nconst weakRef = new WeakRef(target);\n\nconsole.log(weakRef.deref()); // { data: "important" }\ntarget = null; // Object may now be garbage collected\n\n// Later (after GC runs):\n// weakRef.deref() might return undefined\n\n// FinalizationRegistry — cleanup after GC\nconst registry = new FinalizationRegistry((heldValue) => {\n  console.log(`Object with id ${heldValue} was collected`);\n  // Clean up external resources here\n});\n\nlet obj = { id: 1 };\nregistry.register(obj, obj.id); // heldValue = 1\nobj = null; // Eventually logs: "Object with id 1 was collected"\n\n// Practical: memory-sensitive cache\nclass WeakCache {\n  #cache = new Map();\n\n  set(key, value) {\n    this.#cache.set(key, new WeakRef(value));\n  }\n\n  get(key) {\n    const ref = this.#cache.get(key);\n    const value = ref?.deref();\n    if (!value) this.#cache.delete(key); // Clean stale entry\n    return value;\n  }\n}',
  followUp: 'Why should you never rely on `FinalizationRegistry` callbacks for critical application logic?',
  keyTakeaway: '`WeakRef` holds a non-preventing reference to an object; `FinalizationRegistry` triggers cleanup after GC — both are non-deterministic.',
},
{
  id: 26,
  title: 'What is the difference between function declarations and function expressions?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'A function declaration uses the `function` keyword followed by a name and is hoisted entirely, meaning you can call it before the line where it appears in the source code. A function expression assigns a function (named or anonymous) to a variable and is only available after the assignment executes, because only the variable declaration is hoisted (as `undefined`), not the function body. Function declarations are also block-scoped in strict mode but function-scoped in sloppy mode, which can cause subtle bugs. In practice, both create identical function objects at runtime, and the choice between them is mostly about hoisting behavior and code style.',
  codeExample: '// Function declaration — hoisted\ngreet(); // "Hello!"\nfunction greet() {\n  console.log("Hello!");\n}\n\n// Function expression — NOT hoisted\ntry {\n  sayHi(); // TypeError: sayHi is not a function\n} catch (e) {\n  console.log(e.message);\n}\nconst sayHi = function () {\n  console.log("Hi!");\n};',
  followUp: 'What is the difference between a named function expression and an anonymous one, and when would you use each?',
  keyTakeaway: 'Function declarations are fully hoisted; function expressions are not available until the assignment executes.',
},
{
  id: 27,
  title: 'What are arrow functions and how do they differ from regular functions?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'Arrow functions provide a concise syntax using `=>` and differ from regular functions in several key ways. They do not have their own `this` binding — they lexically capture `this` from the enclosing scope at the time they are defined. They also lack an `arguments` object, a `prototype` property, and cannot be used as constructors with `new`. For single-expression bodies, the return is implicit and curly braces are optional, making them ideal for callbacks and functional patterns like `map`, `filter`, and `reduce`.',
  codeExample: '// Regular function\nconst add = function (a, b) {\n  return a + b;\n};\n\n// Arrow function (concise body)\nconst addArrow = (a, b) => a + b;\n\n// Lexical `this`\nconst timer = {\n  seconds: 0,\n  start() {\n    setInterval(() => {\n      this.seconds++; // `this` refers to timer\n      console.log(this.seconds);\n    }, 1000);\n  },\n};',
  followUp: 'Why can you not use an arrow function as a constructor with `new`?',
  keyTakeaway: 'Arrow functions lexically bind `this`, have no `arguments` object, and cannot be used as constructors.',
},
{
  id: 28,
  title: 'What is an IIFE (Immediately Invoked Function Expression)?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'An IIFE is a function that is defined and executed immediately in a single expression. It is created by wrapping a function in parentheses to make it an expression, then appending `()` to invoke it right away. IIFEs were historically used to create a private scope and avoid polluting the global namespace, since JavaScript had no block scoping before `let` and `const`. They are still useful for one-time initialization logic, isolating side effects, and creating closures that capture a specific value in a loop.',
  codeExample: '// Classic IIFE\nconst result = (function () {\n  const secret = 42;\n  return secret * 2;\n})();\nconsole.log(result); // 84\n\n// Arrow IIFE\nconst config = (() => ({\n  env: "production",\n  debug: false,\n}))();\n\n// IIFE with parameters\n(function (global) {\n  global.myLib = { version: "1.0" };\n})(window);',
  followUp: 'With ES modules and `let`/`const` available, are there still valid use cases for IIFEs?',
  keyTakeaway: 'An IIFE is a function defined and called immediately, creating an isolated scope without polluting the global namespace.',
},
{
  id: 29,
  title: 'What is a closure in JavaScript?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'closures',
  answer: 'A closure is formed when a function retains access to variables from its lexical scope even after the outer function that created those variables has finished executing. Every function in JavaScript creates a closure over the scope in which it was defined. This means the inner function "closes over" the variables it references, keeping them alive in memory as long as the inner function exists. Closures are fundamental to patterns like callbacks, event handlers, data privacy, and factory functions.',
  codeExample: 'function createCounter() {\n  let count = 0; // Closed over by the returned function\n  return function () {\n    count++;\n    return count;\n  };\n}\n\nconst counter = createCounter();\nconsole.log(counter()); // 1\nconsole.log(counter()); // 2\nconsole.log(counter()); // 3\n// `count` is not accessible from outside\n// but the inner function still has access to it',
  followUp: 'How do closures interact with the garbage collector, and can they cause memory leaks?',
  keyTakeaway: 'A closure lets a function access variables from its outer scope even after the outer function has returned.',
},
{
  id: 30,
  title: 'What does the `this` keyword refer to in JavaScript?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'this-keyword',
  answer: 'The `this` keyword refers to the object that is currently executing the function, but its value depends on how the function is called, not where it is defined. In a method call like `obj.fn()`, `this` is `obj`. When called as a standalone function, `this` is the global object (`window` in browsers) or `undefined` in strict mode. With `new`, `this` refers to the newly created instance. The `call`, `apply`, and `bind` methods allow you to explicitly set `this` to any value. Arrow functions are the exception — they inherit `this` from their enclosing lexical scope.',
  codeExample: 'const person = {\n  name: "Alice",\n  greet() {\n    console.log(`Hi, I am ${this.name}`);\n  },\n};\n\nperson.greet(); // "Hi, I am Alice"\n\nconst greet = person.greet;\ngreet(); // "Hi, I am undefined" (strict mode)\n\nfunction Dog(name) {\n  this.name = name; // `this` is the new instance\n}\nconst dog = new Dog("Rex");\nconsole.log(dog.name); // "Rex"',
  followUp: 'What is the value of `this` inside a callback passed to `setTimeout`?',
  keyTakeaway: 'The value of `this` is determined by how a function is called, not where it is defined.',
},
{
  id: 31,
  title: 'What are default parameters in function definitions?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'Default parameters allow you to specify fallback values for function arguments that are `undefined` or not provided. Introduced in ES6, they replace the older pattern of using `||` checks inside the function body. Default values are evaluated at call time, not at function definition time, so each invocation gets a fresh default value. They can reference previous parameters in the list, and they can be any expression including function calls. Default parameters only trigger on `undefined`, not on `null` or other falsy values like `0` or `""`.',
  codeExample: 'function createUser(name, role = "viewer", id = Date.now()) {\n  return { name, role, id };\n}\n\nconsole.log(createUser("Alice"));\n// { name: "Alice", role: "viewer", id: 1708300000000 }\n\nconsole.log(createUser("Bob", "admin"));\n// { name: "Bob", role: "admin", id: 1708300000001 }\n\n// Default is NOT triggered by null\nconsole.log(createUser("Eve", null));\n// { name: "Eve", role: null, id: ... }\n\n// Referencing a previous parameter\nfunction greet(name, greeting = `Hello, ${name}!`) {\n  console.log(greeting);\n}\ngreet("Alice"); // "Hello, Alice!"',
  followUp: 'How do default parameters interact with the `arguments` object and destructuring?',
  keyTakeaway: 'Default parameters provide fallback values evaluated at call time and only activate when the argument is `undefined`.',
},
{
  id: 32,
  title: 'What is the difference between `call()`, `apply()`, and `bind()`?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'this-keyword',
  answer: 'All three methods exist on `Function.prototype` and let you control the value of `this` when invoking a function. `call()` invokes the function immediately with a specified `this` value and passes arguments individually. `apply()` also invokes immediately but accepts arguments as an array (or array-like object). `bind()` does not invoke the function; instead, it returns a new function with `this` permanently bound to the specified value. A bound function cannot have its `this` overridden by subsequent `call`, `apply`, or even another `bind`.',
  codeExample: 'function introduce(greeting, punctuation) {\n  console.log(`${greeting}, I am ${this.name}${punctuation}`);\n}\n\nconst user = { name: "Alice" };\n\n// call — args passed individually\nintroduce.call(user, "Hello", "!");\n// "Hello, I am Alice!"\n\n// apply — args passed as array\nintroduce.apply(user, ["Hi", "."]);\n// "Hi, I am Alice."\n\n// bind — returns a new function\nconst boundIntro = introduce.bind(user, "Hey");\nboundIntro("?"); // "Hey, I am Alice?"',
  followUp: 'Can you override the `this` value of a bound function using `call` or `apply`?',
  keyTakeaway: '`call` and `apply` invoke immediately with explicit `this`; `bind` returns a new function with `this` permanently set.',
},
{
  id: 33,
  title: 'What are JavaScript classes and how do they relate to prototypes?',
  difficulty: 'easy',
  topic: 'functions-objects',
  subtopic: 'classes',
  answer: 'JavaScript classes, introduced in ES6, are syntactic sugar over the existing prototype-based inheritance system. A `class` declaration creates a constructor function whose `prototype` property holds the methods defined in the class body. The `extends` keyword sets up the prototype chain for inheritance, and `super` calls the parent constructor or methods. Under the hood, `new MyClass()` works exactly like `new MyConstructor()` — it creates an object, links it to the prototype, and runs the constructor. Classes enforce strict mode, are not hoisted like function declarations, and their methods are non-enumerable by default.',
  codeExample: '// ES6 class\nclass Animal {\n  constructor(name) {\n    this.name = name;\n  }\n  speak() {\n    return `${this.name} makes a sound`;\n  }\n}\n\nclass Dog extends Animal {\n  speak() {\n    return `${this.name} barks`;\n  }\n}\n\nconst dog = new Dog("Rex");\nconsole.log(dog.speak()); // "Rex barks"\nconsole.log(dog instanceof Animal); // true\n\n// Equivalent prototype-based code\nconsole.log(typeof Animal); // "function"\nconsole.log(Dog.prototype.__proto__ === Animal.prototype); // true',
  followUp: 'What are the limitations of classes compared to prototype-based patterns?',
  keyTakeaway: 'Classes are syntactic sugar over prototypes — they create constructor functions with linked prototype objects.',
},
{
  id: 34,
  title: 'How do closures enable data privacy in JavaScript?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'closures',
  answer: 'Closures enable data privacy by allowing variables to exist in a scope that is inaccessible from the outside while still being reachable by inner functions. When a function returns another function (or an object of functions), the returned functions retain access to the outer variables, but no external code can directly read or modify those variables. This pattern effectively simulates private fields, since the only way to interact with the hidden state is through the exposed API. Before private class fields (`#`), closures were the primary mechanism for encapsulation in JavaScript.',
  codeExample: 'function createBankAccount(initialBalance) {\n  let balance = initialBalance; // Private variable\n\n  return {\n    deposit(amount) {\n      if (amount <= 0) throw new Error("Invalid amount");\n      balance += amount;\n      return balance;\n    },\n    withdraw(amount) {\n      if (amount > balance) throw new Error("Insufficient funds");\n      balance -= amount;\n      return balance;\n    },\n    getBalance() {\n      return balance;\n    },\n  };\n}\n\nconst account = createBankAccount(100);\nconsole.log(account.getBalance()); // 100\naccount.deposit(50);\nconsole.log(account.getBalance()); // 150\nconsole.log(account.balance); // undefined (private!)',
  followUp: 'What are the trade-offs of using closures for privacy versus private class fields?',
  keyTakeaway: 'Closures hide variables in an inaccessible outer scope, exposing them only through returned functions.',
},
{
  id: 35,
  title: 'Explain the prototype chain and how property lookup works.',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'prototypes',
  answer: 'When you access a property on an object, JavaScript first looks for it on the object itself. If it is not found, the engine follows the internal `[[Prototype]]` link (accessible via `__proto__` or `Object.getPrototypeOf()`) to the next object in the chain and searches there. This process repeats up the chain until the property is found or `null` is reached at the top (the prototype of `Object.prototype`). This chain of linked objects is called the prototype chain. Property writes always happen on the object itself (unless there is a setter), while reads traverse the chain. This is how inheritance works in JavaScript.',
  codeExample: 'const animal = {\n  type: "animal",\n  speak() {\n    return `${this.name} is a ${this.type}`;\n  },\n};\n\nconst dog = Object.create(animal);\ndog.name = "Rex";\ndog.type = "dog";\n\nconsole.log(dog.speak()); // "Rex is a dog"\nconsole.log(dog.hasOwnProperty("name")); // true\nconsole.log(dog.hasOwnProperty("speak")); // false\n\n// Traversing the chain\nconsole.log(Object.getPrototypeOf(dog) === animal); // true\nconsole.log(Object.getPrototypeOf(animal) === Object.prototype); // true\nconsole.log(Object.getPrototypeOf(Object.prototype)); // null',
  followUp: 'What is the performance impact of deeply nested prototype chains?',
  keyTakeaway: 'JavaScript resolves properties by walking up the prototype chain until found or `null` is reached.',
},
{
  id: 36,
  title: 'What are higher-order functions? Give examples.',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'higher-order',
  answer: 'A higher-order function is a function that either takes one or more functions as arguments, returns a function, or both. This is possible because functions in JavaScript are first-class citizens — they can be assigned to variables, passed as arguments, and returned from other functions. Built-in array methods like `map`, `filter`, `reduce`, `sort`, and `forEach` are higher-order functions because they accept a callback. Higher-order functions enable powerful patterns like function composition, decorators, and middleware chains.',
  codeExample: '// Takes a function as argument\nconst numbers = [1, 2, 3, 4, 5];\nconst doubled = numbers.map((n) => n * 2);\nconsole.log(doubled); // [2, 4, 6, 8, 10]\n\n// Returns a function\nfunction multiplier(factor) {\n  return (number) => number * factor;\n}\nconst triple = multiplier(3);\nconsole.log(triple(5)); // 15\n\n// Both: takes a fn, returns a fn (decorator)\nfunction withLogging(fn) {\n  return function (...args) {\n    console.log(`Calling with: ${args}`);\n    const result = fn(...args);\n    console.log(`Result: ${result}`);\n    return result;\n  };\n}\nconst loggedAdd = withLogging((a, b) => a + b);\nloggedAdd(2, 3); // Logs: Calling with: 2,3 → Result: 5',
  followUp: 'How does `reduce` work as a higher-order function, and can you implement `map` using `reduce`?',
  keyTakeaway: 'Higher-order functions accept or return other functions, enabling composition, abstraction, and reuse.',
},
{
  id: 37,
  title: 'What is function currying and how is it implemented?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'currying',
  answer: 'Currying transforms a function that takes multiple arguments into a sequence of functions that each take a single argument. Instead of calling `f(a, b, c)`, you call `f(a)(b)(c)`. This enables partial application, where you fix some arguments to create specialized functions. Currying is implemented by returning nested functions, each capturing one argument in its closure until all arguments are collected. A generic `curry` utility can detect when enough arguments have been provided and then invoke the original function.',
  codeExample: '// Manual currying\nfunction add(a) {\n  return function (b) {\n    return a + b;\n  };\n}\nconsole.log(add(2)(3)); // 5\n\nconst addTen = add(10);\nconsole.log(addTen(5)); // 15\n\n// Generic curry utility\nfunction curry(fn) {\n  return function curried(...args) {\n    if (args.length >= fn.length) {\n      return fn.apply(this, args);\n    }\n    return function (...nextArgs) {\n      return curried.apply(this, args.concat(nextArgs));\n    };\n  };\n}\n\nconst curriedSum = curry((a, b, c) => a + b + c);\nconsole.log(curriedSum(1)(2)(3)); // 6\nconsole.log(curriedSum(1, 2)(3)); // 6\nconsole.log(curriedSum(1)(2, 3)); // 6',
  followUp: 'What is the difference between currying and partial application?',
  keyTakeaway: 'Currying transforms a multi-argument function into a chain of single-argument functions using closures.',
},
{
  id: 38,
  title: 'How does `this` behave differently in arrow functions vs regular functions?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'this-keyword',
  answer: 'Regular functions determine `this` dynamically at call time based on how they are invoked — as a method, standalone call, with `new`, or via `call`/`apply`/`bind`. Arrow functions, by contrast, capture `this` lexically from the enclosing scope at definition time and never change it. This means `call`, `apply`, and `bind` cannot override an arrow function\'s `this`. This lexical binding makes arrow functions ideal for callbacks inside methods, where a regular function would lose the method\'s `this`. However, it also means arrow functions should not be used as object methods or constructors, since they will not bind `this` to the instance.',
  codeExample: 'const obj = {\n  value: 42,\n  // Regular function: `this` is obj\n  getRegular() {\n    return function () {\n      console.log(this.value); // undefined (lost `this`)\n    };\n  },\n  // Arrow function: `this` captured from getArrow\n  getArrow() {\n    return () => {\n      console.log(this.value); // 42\n    };\n  },\n};\n\nobj.getRegular()(); // undefined\nobj.getArrow()();   // 42\n\n// bind/call cannot change arrow `this`\nconst arrow = () => this;\nconsole.log(arrow.call({ x: 1 })); // still outer `this`',
  followUp: 'What happens if you use an arrow function as an object method defined in an object literal?',
  keyTakeaway: 'Arrow functions capture `this` lexically at definition time; regular functions resolve `this` dynamically at call time.',
},
{
  id: 39,
  title: 'What is the `new` keyword and what happens when you use it?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'prototypes',
  answer: 'The `new` keyword invokes a function as a constructor and performs four steps internally. First, it creates a brand-new empty object. Second, it sets the new object\'s internal `[[Prototype]]` to the constructor\'s `prototype` property. Third, it executes the constructor function with `this` bound to the new object, allowing the constructor to initialize properties. Fourth, if the constructor does not explicitly return an object, `new` returns the newly created object. If the constructor returns a non-object primitive, that return value is ignored and the new object is returned instead.',
  codeExample: 'function Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\nPerson.prototype.greet = function () {\n  return `Hi, I am ${this.name}`;\n};\n\nconst alice = new Person("Alice", 30);\nconsole.log(alice.greet()); // "Hi, I am Alice"\nconsole.log(alice instanceof Person); // true\n\n// What `new` does internally (simplified)\nfunction simulateNew(Constructor, ...args) {\n  const obj = Object.create(Constructor.prototype);\n  const result = Constructor.apply(obj, args);\n  return result instanceof Object ? result : obj;\n}\n\nconst bob = simulateNew(Person, "Bob", 25);\nconsole.log(bob.greet()); // "Hi, I am Bob"',
  followUp: 'What happens if a constructor explicitly returns an object versus a primitive?',
  keyTakeaway: 'The `new` keyword creates an object, links its prototype, executes the constructor with `this` bound to it, then returns the object.',
},
{
  id: 40,
  title: 'Explain the difference between `__proto__` and `prototype`.',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'prototypes',
  answer: '`prototype` is a property that exists on functions (specifically constructors) and is the object that will become the `[[Prototype]]` of instances created with `new`. In contrast, `__proto__` (or `Object.getPrototypeOf()`) is an accessor on every object that points to the object from which it inherits — its actual prototype in the chain. When you write `new Foo()`, the resulting object\'s `__proto__` is set to `Foo.prototype`. Every function has a `prototype` property, but only constructor functions use it meaningfully. The `__proto__` accessor is deprecated in favor of `Object.getPrototypeOf()` and `Object.setPrototypeOf()`.',
  codeExample: 'function Cat(name) {\n  this.name = name;\n}\nCat.prototype.meow = function () {\n  return `${this.name} says meow`;\n};\n\nconst kitty = new Cat("Whiskers");\n\n// `prototype` lives on the constructor function\nconsole.log(typeof Cat.prototype); // "object"\nconsole.log(Cat.prototype.meow); // [Function: meow]\n\n// `__proto__` lives on instances (the actual link)\nconsole.log(kitty.__proto__ === Cat.prototype); // true\nconsole.log(Object.getPrototypeOf(kitty) === Cat.prototype); // true\n\n// Instances do NOT have a `prototype` property\nconsole.log(kitty.prototype); // undefined',
  followUp: 'Why is `__proto__` deprecated, and what should you use instead?',
  keyTakeaway: '`prototype` is the blueprint on constructors; `__proto__` is the actual chain link on instances pointing to that blueprint.',
},
{
  id: 41,
  title: 'What are getters and setters in JavaScript?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'classes',
  answer: 'Getters and setters are special methods that let you define computed properties on objects and classes. A getter is defined with `get` and is called automatically when the property is read, while a setter is defined with `set` and is called when the property is assigned a value. They allow you to run logic on property access without requiring the consumer to call a method explicitly. This is useful for validation, computed values, lazy initialization, and maintaining invariants. Under the hood, they are defined as accessor descriptors via `Object.defineProperty`.',
  codeExample: 'class Temperature {\n  #celsius;\n\n  constructor(celsius) {\n    this.#celsius = celsius;\n  }\n\n  get fahrenheit() {\n    return this.#celsius * 9 / 5 + 32;\n  }\n\n  set fahrenheit(value) {\n    this.#celsius = (value - 32) * 5 / 9;\n  }\n\n  get celsius() {\n    return this.#celsius;\n  }\n}\n\nconst temp = new Temperature(100);\nconsole.log(temp.fahrenheit); // 212 (getter)\ntemp.fahrenheit = 32;         // setter\nconsole.log(temp.celsius);    // 0\n\n// Object literal getters/setters\nconst user = {\n  first: "Alice",\n  last: "Smith",\n  get fullName() {\n    return `${this.first} ${this.last}`;\n  },\n};',
  followUp: 'How can you use `Object.defineProperty` to create a getter/setter on an existing object?',
  keyTakeaway: 'Getters and setters intercept property reads and writes, enabling computed values and validation.',
},
{
  id: 42,
  title: 'What is composition vs inheritance and when should you use each?',
  difficulty: 'medium',
  topic: 'functions-objects',
  subtopic: 'composition',
  answer: 'Inheritance creates an "is-a" relationship where a child class extends a parent and inherits its methods and properties through the prototype chain. Composition creates a "has-a" relationship where an object is built by combining smaller, focused objects or functions that provide specific capabilities. Composition is generally preferred because it avoids tight coupling, the fragile base class problem, and deep inheritance hierarchies. It also allows you to mix and match behaviors freely, whereas single-inheritance forces a rigid tree structure. Use inheritance when there is a clear taxonomic relationship; use composition when you need flexible behavior reuse.',
  codeExample: '// Inheritance — rigid hierarchy\nclass Animal {\n  eat() { return "eating"; }\n}\nclass Dog extends Animal {\n  bark() { return "woof"; }\n}\n\n// Composition — flexible behaviors\nconst canEat = (state) => ({\n  eat: () => `${state.name} is eating`,\n});\nconst canBark = (state) => ({\n  bark: () => `${state.name} says woof`,\n});\nconst canSwim = (state) => ({\n  swim: () => `${state.name} is swimming`,\n});\n\nfunction createDog(name) {\n  const state = { name };\n  return {\n    ...canEat(state),\n    ...canBark(state),\n  };\n}\n\nfunction createDuck(name) {\n  const state = { name };\n  return {\n    ...canEat(state),\n    ...canSwim(state),\n  };\n}\n\nconst dog = createDog("Rex");\nconsole.log(dog.eat());  // "Rex is eating"\nconsole.log(dog.bark()); // "Rex says woof"',
  followUp: 'What is the "gorilla-banana" problem with inheritance?',
  keyTakeaway: 'Favor composition over inheritance — combine small focused behaviors instead of building deep class hierarchies.',
},
{
  id: 43,
  title: 'Explain all four `this` binding rules and their precedence.',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'this-keyword',
  answer: 'JavaScript has four rules for determining `this`, in order of precedence from highest to lowest. First, `new` binding: when called with `new`, `this` is the newly created object. Second, explicit binding: `call`, `apply`, or `bind` set `this` to the first argument. Third, implicit binding: when called as a method on an object (`obj.fn()`), `this` is that object. Fourth, default binding: in a standalone call, `this` is the global object or `undefined` in strict mode. The `new` binding beats explicit binding (you can `new` a bound function), explicit beats implicit, and implicit beats default. Arrow functions bypass all four rules because they use lexical `this`.',
  codeExample: 'function identify() {\n  return this.name;\n}\n\nconst alice = { name: "Alice" };\nconst bob = { name: "Bob" };\n\n// Rule 4: Default binding\n// identify(); // undefined (strict) or global name\n\n// Rule 3: Implicit binding\nalice.identify = identify;\nconsole.log(alice.identify()); // "Alice"\n\n// Rule 2: Explicit binding beats implicit\nconsole.log(identify.call(bob)); // "Bob"\n\n// Rule 1: `new` binding beats explicit\nconst BoundCtor = identify.bind(alice);\nconsole.log(BoundCtor()); // "Alice" (bind wins over default)\nconst obj = new BoundCtor();\nconsole.log(obj); // {} — `new` overrides bind\n\n// Arrow functions: lexical, ignores all rules\nconst arrow = () => this;\nconsole.log(arrow.call(alice)); // outer `this`, not alice',
  followUp: 'How does `this` behave in an event handler attached to a DOM element, and how does that fit into these rules?',
  keyTakeaway: 'The four `this` rules in precedence order: `new` > explicit (`bind`/`call`/`apply`) > implicit (method) > default (global).',
},
{
  id: 44,
  title: 'Implement a memoization function that caches results.',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'closures',
  answer: 'Memoization is an optimization technique that caches the results of expensive function calls and returns the cached result when the same inputs occur again. A memoize wrapper uses a closure to maintain a cache (typically a `Map`) that maps argument keys to results. The key challenge is creating a reliable cache key from the arguments — using `JSON.stringify` works for serializable values, but a `Map` with complex key strategies handles more cases. For single-argument functions, the argument itself can be the key. Advanced implementations may use a `WeakMap` for object arguments to prevent memory leaks.',
  codeExample: '// Basic memoize with Map\nfunction memoize(fn) {\n  const cache = new Map();\n  return function (...args) {\n    const key = JSON.stringify(args);\n    if (cache.has(key)) {\n      console.log("Cache hit");\n      return cache.get(key);\n    }\n    const result = fn.apply(this, args);\n    cache.set(key, result);\n    return result;\n  };\n}\n\nconst fibonacci = memoize(function fib(n) {\n  if (n <= 1) return n;\n  return fibonacci(n - 1) + fibonacci(n - 2);\n});\n\nconsole.log(fibonacci(40)); // Fast: 102334155\n\n// With max cache size (LRU-like)\nfunction memoizeWithLimit(fn, maxSize = 100) {\n  const cache = new Map();\n  return function (...args) {\n    const key = JSON.stringify(args);\n    if (cache.has(key)) {\n      const val = cache.get(key);\n      cache.delete(key);\n      cache.set(key, val); // Move to end (most recent)\n      return val;\n    }\n    const result = fn.apply(this, args);\n    cache.set(key, result);\n    if (cache.size > maxSize) {\n      cache.delete(cache.keys().next().value);\n    }\n    return result;\n  };\n}',
  followUp: 'How would you handle memoization for functions that accept objects as arguments without memory leaks?',
  keyTakeaway: 'Memoization uses closures to cache function results in a `Map`, trading memory for speed on repeated calls.',
},
{
  id: 45,
  title: 'What is the module pattern and how does it use closures?',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'closures',
  answer: 'The module pattern uses an IIFE combined with closures to create a self-contained unit with private state and a public API. Variables declared inside the IIFE are private by default — they cannot be accessed from outside. The IIFE returns an object containing methods that close over the private variables, forming the public interface. This pattern was the primary way to achieve encapsulation before ES modules. The revealing module pattern is a variation where all functions are defined privately and only references to public functions are returned, making it easier to see the public API at a glance.',
  codeExample: '// Classic module pattern\nconst Counter = (function () {\n  let count = 0;          // Private state\n  const MAX = 100;        // Private constant\n\n  function increment() {  // Private helper\n    if (count < MAX) count++;\n  }\n\n  return {                // Public API\n    next() {\n      increment();\n      return count;\n    },\n    reset() {\n      count = 0;\n    },\n    getCount() {\n      return count;\n    },\n  };\n})();\n\nconsole.log(Counter.next());     // 1\nconsole.log(Counter.next());     // 2\nCounter.reset();\nconsole.log(Counter.getCount()); // 0\nconsole.log(Counter.count);      // undefined (private)\n\n// Revealing module pattern\nconst Logger = (function () {\n  const logs = [];\n  function add(msg) { logs.push({ msg, time: Date.now() }); }\n  function getAll() { return [...logs]; }\n  function clear() { logs.length = 0; }\n  return { add, getAll, clear }; // Reveal only these\n})();',
  followUp: 'How do ES modules differ from the module pattern, and what advantages do they offer?',
  keyTakeaway: 'The module pattern uses an IIFE and closures to expose a public API while keeping internal state truly private.',
},
{
  id: 46,
  title: 'What are Proxy and Reflect and how do they enable metaprogramming?',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'prototypes',
  answer: '`Proxy` creates a wrapper around an object that intercepts and redefines fundamental operations like property access, assignment, function invocation, and enumeration through handler functions called traps. `Reflect` is a companion object that provides the default behavior for each trap as static methods, making it easy to forward operations after custom logic. Together, they enable metaprogramming — writing code that manipulates the behavior of other code at runtime. Common use cases include validation, logging, lazy loading, negative array indexing, observable objects, and implementing reactivity systems like those in Vue.js.',
  codeExample: '// Validation proxy\nconst validator = {\n  set(target, prop, value) {\n    if (prop === "age" && typeof value !== "number") {\n      throw new TypeError("Age must be a number");\n    }\n    if (prop === "age" && (value < 0 || value > 150)) {\n      throw new RangeError("Age must be between 0 and 150");\n    }\n    return Reflect.set(target, prop, value);\n  },\n  get(target, prop) {\n    if (!(prop in target)) {\n      throw new ReferenceError(`Property "${prop}" does not exist`);\n    }\n    return Reflect.get(target, prop);\n  },\n};\n\nconst person = new Proxy({ name: "Alice", age: 30 }, validator);\nperson.age = 25;   // OK\n// person.age = -5; // RangeError\n// person.foo;      // ReferenceError\n\n// Negative array indexing\nconst negativeIndex = {\n  get(target, prop) {\n    const index = Number(prop);\n    if (index < 0) return target[target.length + index];\n    return Reflect.get(target, prop);\n  },\n};\nconst arr = new Proxy([1, 2, 3, 4], negativeIndex);\nconsole.log(arr[-1]); // 4',
  followUp: 'What are the performance implications of using Proxy in hot code paths?',
  keyTakeaway: '`Proxy` intercepts object operations via traps, and `Reflect` provides defaults, enabling powerful runtime metaprogramming.',
},
{
  id: 47,
  title: 'Explain the different prototypal inheritance patterns in JavaScript.',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'prototypes',
  answer: 'JavaScript supports several prototypal inheritance patterns. Constructor pattern: uses `new` with constructor functions that assign properties to `this` and place shared methods on the `prototype`. Prototypal (Crockford) pattern: uses `Object.create()` to directly set one object as the prototype of another, without constructors. Parasitic pattern: creates an object via `Object.create()`, augments it with new properties, then returns it — useful when you want to add to an inherited object without modifying the prototype. Class pattern: ES6 `class` syntax that desugars to constructor plus prototype but with cleaner syntax and `super` support. Factory pattern: returns plain objects from functions, using closures for privacy instead of prototypes.',
  codeExample: '// 1. Constructor pattern\nfunction Vehicle(make) {\n  this.make = make;\n}\nVehicle.prototype.start = function () {\n  return `${this.make} started`;\n};\n\n// 2. Prototypal (Object.create)\nconst vehicleProto = {\n  start() { return `${this.make} started`; },\n};\nconst car = Object.create(vehicleProto);\ncar.make = "Toyota";\n\n// 3. Parasitic inheritance\nfunction createElectricVehicle(make) {\n  const vehicle = Object.create(vehicleProto);\n  vehicle.make = make;\n  vehicle.charge = function () {\n    return `${this.make} is charging`;\n  };\n  return vehicle;\n}\n\n// 4. ES6 Class pattern\nclass Bike extends Vehicle {\n  ride() { return `${this.make} riding`; }\n}\n\n// 5. Factory with closures (no prototype)\nfunction createVehicle(make) {\n  return {\n    start: () => `${make} started`,\n  };\n}\n\nconsole.log(car.start());                   // "Toyota started"\nconsole.log(createElectricVehicle("Tesla").charge()); // "Tesla is charging"\nconsole.log(new Bike("Honda").ride());      // "Honda riding"',
  followUp: 'What are the memory trade-offs between sharing methods on the prototype vs defining them in a factory closure?',
  keyTakeaway: 'JavaScript offers constructor, prototypal, parasitic, class, and factory patterns, each trading off clarity, encapsulation, and memory.',
},
{
  id: 48,
  title: 'What are generator functions and how do they maintain state?',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'Generator functions, declared with `function*`, return a generator object that conforms to both the iterator and iterable protocols. When `next()` is called, the function executes until the next `yield` expression, which pauses execution and returns the yielded value. The function\'s entire execution context — local variables, instruction pointer, and scope — is preserved between pauses. Calling `next(value)` resumes execution, and `value` becomes the result of the `yield` expression. Generators can delegate to other generators with `yield*`. They are useful for lazy sequences, async flow control (before `async`/`await`), and implementing custom iterables.',
  codeExample: 'function* fibonacci() {\n  let a = 0, b = 1;\n  while (true) {\n    yield a;\n    [a, b] = [b, a + b];\n  }\n}\n\nconst fib = fibonacci();\nconsole.log(fib.next().value); // 0\nconsole.log(fib.next().value); // 1\nconsole.log(fib.next().value); // 1\nconsole.log(fib.next().value); // 2\n\n// Two-way communication\nfunction* accumulator() {\n  let total = 0;\n  while (true) {\n    const value = yield total;\n    total += value;\n  }\n}\n\nconst acc = accumulator();\nacc.next();           // Initialize (yields 0)\nconsole.log(acc.next(10).value); // 10\nconsole.log(acc.next(20).value); // 30\nconsole.log(acc.next(5).value);  // 35\n\n// Lazy take utility\nfunction* take(n, iterable) {\n  let i = 0;\n  for (const value of iterable) {\n    if (i++ >= n) return;\n    yield value;\n  }\n}\nconsole.log([...take(5, fibonacci())]); // [0, 1, 1, 2, 3]',
  followUp: 'How do generators relate to `async`/`await` under the hood?',
  keyTakeaway: 'Generators pause and resume execution at `yield` points, preserving their full state between calls.',
},
{
  id: 49,
  title: 'How do private class fields (`#field`) work and how do they differ from closures?',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'classes',
  answer: 'Private class fields, prefixed with `#`, provide truly private instance data enforced at the language level. Accessing a `#field` outside the class body throws a `SyntaxError`, and the privacy is enforced at parse time, not runtime. Unlike closure-based privacy where each instance gets its own copy of methods, private fields allow methods to remain on the prototype (shared across instances) while the fields are still per-instance and private. One key difference is that private fields are accessible to other instances of the same class (for example, in an `equals` method), whereas closure-based private variables are truly instance-private. Private fields also support `#method()` syntax and static private fields.',
  codeExample: 'class BankAccount {\n  #balance; // Private field\n  #owner;\n\n  constructor(owner, balance) {\n    this.#owner = owner;\n    this.#balance = balance;\n  }\n\n  deposit(amount) {\n    if (amount <= 0) throw new Error("Invalid amount");\n    this.#balance += amount;\n  }\n\n  get balance() {\n    return this.#balance;\n  }\n\n  // Can access private fields of OTHER instances of same class\n  transfer(amount, target) {\n    if (amount > this.#balance) throw new Error("Insufficient funds");\n    this.#balance -= amount;\n    target.#balance += amount; // Accessing another instance\'s private field\n  }\n\n  // Private method\n  #validate() {\n    return this.#balance >= 0;\n  }\n}\n\nconst a = new BankAccount("Alice", 100);\nconst b = new BankAccount("Bob", 50);\na.transfer(30, b);\nconsole.log(a.balance); // 70\nconsole.log(b.balance); // 80\n// console.log(a.#balance); // SyntaxError',
  followUp: 'Can you use `in` to check if an object has a private field, and how does `#field in obj` work?',
  keyTakeaway: 'Private fields use `#` for language-enforced privacy with shared prototype methods, unlike closures which duplicate methods per instance.',
},
{
  id: 50,
  title: 'What is tail call optimization and does JavaScript support it?',
  difficulty: 'hard',
  topic: 'functions-objects',
  subtopic: 'functions',
  answer: 'Tail call optimization (TCO) is a compiler optimization where a function call in the tail position (the very last action before return) reuses the current stack frame instead of creating a new one, preventing stack overflow in deep recursion. ES2015 specifies proper tail calls (PTC) in strict mode, but as of today, only Safari/JavaScriptCore implements it. V8 (Chrome/Node.js) and SpiderMonkey (Firefox) chose not to implement PTC due to debugging difficulties (stack traces are lost) and performance concerns. The workaround for other engines is to use trampolining — a loop that repeatedly calls returned thunks — or convert recursion to iteration.',
  codeExample: '// Tail call: the recursive call IS the return value\n"use strict";\nfunction factorialTCO(n, acc = 1) {\n  if (n <= 1) return acc;\n  return factorialTCO(n - 1, n * acc); // Tail position\n}\n\n// NOT a tail call: multiplication happens AFTER the recursive call\nfunction factorialBad(n) {\n  if (n <= 1) return 1;\n  return n * factorialBad(n - 1); // Not tail position\n}\n\n// Trampoline: works in all engines\nfunction trampoline(fn) {\n  return function (...args) {\n    let result = fn(...args);\n    while (typeof result === "function") {\n      result = result();\n    }\n    return result;\n  };\n}\n\nconst factorial = trampoline(function fact(n, acc = 1) {\n  if (n <= 1) return acc;\n  return () => fact(n - 1, n * acc); // Return thunk\n});\n\nconsole.log(factorial(100000)); // Infinity (no stack overflow)',
  followUp: 'What is a trampoline and how does it simulate tail call optimization?',
  keyTakeaway: 'Tail call optimization reuses stack frames for tail-position calls, but only Safari implements it — use trampolining elsewhere.',
},
{
id: 51,
title: 'What is the difference between synchronous and asynchronous code?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'event-loop',
answer: 'Synchronous code executes line by line, blocking subsequent operations until the current one completes. Asynchronous code allows the program to continue executing while waiting for an operation like a network request or timer to finish. JavaScript uses an event loop to manage async operations — when an async task completes, its callback is placed in a queue and executed when the call stack is empty. This non-blocking model is essential because JavaScript is single-threaded.',
codeExample: '// Synchronous — blocks until done\nconsole.log("First");\nconsole.log("Second");\nconsole.log("Third");\n// Output: First, Second, Third\n\n// Asynchronous — non-blocking\nconsole.log("First");\nsetTimeout(() => console.log("Second"), 0);\nconsole.log("Third");\n// Output: First, Third, Second',
followUp: 'Why is JavaScript single-threaded yet still able to handle concurrent operations?',
keyTakeaway: 'Synchronous code blocks execution while asynchronous code lets the program continue and handles results later via the event loop.',
  },
  {
id: 52,
title: 'What is a callback function?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'callbacks',
answer: 'A callback is a function passed as an argument to another function, which is then invoked at a later time — either synchronously or asynchronously. In Node.js, callbacks traditionally follow the error-first pattern where the first parameter is an error object and the second is the result. Callbacks are the foundational async pattern in JavaScript, used by APIs like `setTimeout`, `addEventListener`, and `Array.prototype.map`. While simple, deeply nested callbacks can lead to hard-to-read code known as callback hell.',
codeExample: '// Synchronous callback\nconst numbers = [1, 2, 3];\nnumbers.forEach((n) => console.log(n));\n\n// Asynchronous callback\nfunction fetchData(url, callback) {\n  setTimeout(() => {\n    const data = { id: 1, name: "Alice" };\n    callback(null, data);\n  }, 1000);\n}\n\n// Error-first callback pattern\nfetchData("/api/user", (err, data) => {\n  if (err) {\n    console.error("Failed:", err);\n    return;\n  }\n  console.log(data);\n});',
followUp: 'What is the difference between a synchronous and an asynchronous callback?',
keyTakeaway: 'A callback is a function passed to another function to be executed later, forming the basis of async programming in JavaScript.',
  },
  {
id: 53,
title: 'What are Promises and what states can they be in?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'promises',
answer: 'A Promise is an object representing the eventual completion or failure of an asynchronous operation. It exists in one of three states: `pending` (initial state, neither fulfilled nor rejected), `fulfilled` (the operation completed successfully), or `rejected` (the operation failed). Once a Promise transitions from `pending` to either `fulfilled` or `rejected`, it is said to be settled and its state cannot change again. You attach handlers using `.then()` for success and `.catch()` for errors.',
codeExample: '// Creating a Promise\nconst promise = new Promise((resolve, reject) => {\n  const success = true;\n  if (success) {\n    resolve("Data loaded");\n  } else {\n    reject(new Error("Failed to load"));\n  }\n});\n\n// Consuming a Promise\npromise\n  .then((value) => console.log(value))   // "Data loaded"\n  .catch((err) => console.error(err))\n  .finally(() => console.log("Done"));   // Always runs',
followUp: 'What is the difference between a resolved Promise and a fulfilled Promise?',
keyTakeaway: 'A Promise represents a future value and can be pending, fulfilled, or rejected — once settled its state is immutable.',
  },
  {
id: 54,
title: 'What is the `async`/`await` syntax?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'async-await',
answer: 'The `async` keyword before a function declaration makes it return a Promise automatically. The `await` keyword can only be used inside an `async` function (or at the top level of a module) and pauses execution until the awaited Promise settles. If the Promise fulfills, `await` returns the resolved value; if it rejects, it throws the rejection reason. This syntax makes asynchronous code read like synchronous code, dramatically improving readability over chained `.then()` calls.',
codeExample: '// Without async/await\nfunction fetchUser() {\n  return fetch("/api/user")\n    .then((res) => res.json())\n    .then((data) => data);\n}\n\n// With async/await\nasync function fetchUser() {\n  const res = await fetch("/api/user");\n  const data = await res.json();\n  return data;\n}\n\n// The return value is always a Promise\nfetchUser().then((user) => console.log(user));',
followUp: 'What happens if you forget to use `await` before an async function call?',
keyTakeaway: '`async`/`await` is syntactic sugar over Promises that lets you write asynchronous code in a synchronous style.',
  },
  {
id: 55,
title: 'What is `setTimeout` and how does it work?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'timers',
answer: '`setTimeout` schedules a callback function to execute after a minimum delay specified in milliseconds. It returns a timer ID that can be passed to `clearTimeout` to cancel the scheduled execution. The delay is not guaranteed to be exact — it represents the minimum time before the callback is added to the macrotask queue. The actual execution depends on the event loop; if the call stack is busy, the callback will wait longer than the specified delay.',
codeExample: '// Basic usage\nconst timerId = setTimeout(() => {\n  console.log("Executed after ~2 seconds");\n}, 2000);\n\n// Cancel before it fires\nclearTimeout(timerId);\n\n// setTimeout(fn, 0) does NOT execute immediately\nconsole.log("A");\nsetTimeout(() => console.log("B"), 0);\nconsole.log("C");\n// Output: A, C, B\n// "B" waits for the call stack to clear',
followUp: 'Why does `setTimeout(fn, 0)` not execute the callback immediately?',
keyTakeaway: '`setTimeout` schedules a callback after a minimum delay, but exact timing depends on the event loop and call stack.',
  },
  {
id: 56,
title: 'What is the Event Loop in JavaScript?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'event-loop',
answer: 'The event loop is the mechanism that allows JavaScript to perform non-blocking operations despite being single-threaded. It continuously checks the call stack — when the stack is empty, it picks the next task from the task queues and pushes it onto the stack for execution. The event loop processes microtasks (like Promise callbacks) before macrotasks (like `setTimeout` callbacks) in each iteration. This architecture enables JavaScript to handle I/O, timers, and user interactions without blocking the main thread.',
codeExample: '// Demonstrates event loop ordering\nconsole.log("1 - Script start");\n\nsetTimeout(() => {\n  console.log("2 - setTimeout");\n}, 0);\n\nPromise.resolve().then(() => {\n  console.log("3 - Promise");\n});\n\nconsole.log("4 - Script end");\n\n// Output:\n// 1 - Script start\n// 4 - Script end\n// 3 - Promise     (microtask, runs first)\n// 2 - setTimeout  (macrotask, runs after)',
followUp: 'What is the difference between the call stack and the task queue?',
keyTakeaway: 'The event loop continuously moves tasks from queues to the call stack, processing microtasks before macrotasks each cycle.',
  },
  {
id: 57,
title: 'What is the difference between `setTimeout` and `setInterval`?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'timers',
answer: '`setTimeout` executes a callback once after a specified delay, while `setInterval` repeatedly executes a callback at the specified interval until cleared with `clearInterval`. A key difference is that `setInterval` does not account for the execution time of the callback — if the callback takes longer than the interval, invocations can stack up. For this reason, recursive `setTimeout` is often preferred over `setInterval` because it guarantees a consistent delay between the end of one execution and the start of the next.',
codeExample: '// setTimeout — runs once\nsetTimeout(() => console.log("Once"), 1000);\n\n// setInterval — runs repeatedly\nconst id = setInterval(() => {\n  console.log("Repeating");\n}, 1000);\nclearInterval(id); // Stop it\n\n// Preferred: recursive setTimeout\nfunction poll() {\n  setTimeout(async () => {\n    const data = await fetch("/api/status");\n    console.log(await data.json());\n    poll(); // Schedule next AFTER completion\n  }, 1000);\n}\npoll();',
followUp: 'Why might `setInterval` drift over time and how can you correct for it?',
keyTakeaway: '`setTimeout` fires once while `setInterval` fires repeatedly, but recursive `setTimeout` is often safer for repeated tasks.',
  },
  {
id: 58,
title: 'How do you handle errors in Promise chains?',
difficulty: 'easy',
topic: 'async-patterns',
subtopic: 'error-handling',
answer: 'Errors in Promise chains are handled using `.catch()`, which catches any rejection or thrown error from preceding `.then()` handlers. A `.catch()` at the end of a chain acts as a catch-all for any error in the chain. You can also place `.catch()` mid-chain to recover from errors and continue processing. The `.finally()` method runs regardless of whether the Promise fulfilled or rejected, making it ideal for cleanup logic like hiding loading spinners.',
codeExample: 'fetch("/api/data")\n  .then((res) => {\n    if (!res.ok) throw new Error(`HTTP ${res.status}`);\n    return res.json();\n  })\n  .then((data) => {\n    console.log(data);\n  })\n  .catch((err) => {\n    console.error("Request failed:", err.message);\n  })\n  .finally(() => {\n    console.log("Cleanup: hide spinner");\n  });\n\n// Mid-chain recovery\nPromise.reject("fail")\n  .catch(() => "default value")  // Recovers\n  .then((val) => console.log(val)); // "default value"',
followUp: 'What happens if a Promise rejects but there is no `.catch()` handler?',
keyTakeaway: 'Use `.catch()` to handle rejections in Promise chains and `.finally()` for cleanup that runs regardless of outcome.',
  },
  {
id: 59,
title: 'Explain the microtask queue vs the macrotask queue.',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'microtasks',
answer: 'The microtask queue and macrotask queue are two separate queues in the event loop with different priorities. Microtasks include Promise callbacks (`.then`, `.catch`, `.finally`), `queueMicrotask()`, and `MutationObserver` callbacks. Macrotasks include `setTimeout`, `setInterval`, `setImmediate` (Node.js), and I/O callbacks. After each macrotask completes, the event loop drains the entire microtask queue before moving to the next macrotask. This means microtasks have higher priority and can starve macrotasks if they continuously enqueue more microtasks.',
codeExample: 'console.log("1 - sync");\n\nsetTimeout(() => console.log("2 - macrotask"), 0);\n\nPromise.resolve()\n  .then(() => console.log("3 - microtask 1"))\n  .then(() => console.log("4 - microtask 2"));\n\nqueueMicrotask(() => console.log("5 - microtask 3"));\n\nconsole.log("6 - sync");\n\n// Output:\n// 1 - sync\n// 6 - sync\n// 3 - microtask 1\n// 5 - microtask 3\n// 4 - microtask 2\n// 2 - macrotask',
followUp: 'Can microtasks starve macrotasks, and if so, how would you detect this?',
keyTakeaway: 'Microtasks (Promises) are fully drained after each macrotask, giving them higher priority than macrotasks (timers).',
  },
  {
id: 60,
title: 'What is `Promise.all()` and how does it differ from `Promise.allSettled()`?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'promises',
answer: '`Promise.all()` takes an iterable of Promises and returns a single Promise that fulfills with an array of results when all input Promises fulfill, or rejects immediately when any one Promise rejects. `Promise.allSettled()` also takes an iterable but always waits for all Promises to settle, returning an array of objects with `status` (`"fulfilled"` or `"rejected"`) and either `value` or `reason`. Use `Promise.all()` when all results are required and any failure should abort, and `Promise.allSettled()` when you need results from all operations regardless of individual failures.',
codeExample: '// Promise.all — fails fast\nconst p1 = Promise.resolve(1);\nconst p2 = Promise.reject("error");\nconst p3 = Promise.resolve(3);\n\nPromise.all([p1, p2, p3])\n  .then((vals) => console.log(vals))\n  .catch((err) => console.log(err)); // "error"\n\n// Promise.allSettled — waits for all\nPromise.allSettled([p1, p2, p3])\n  .then((results) => {\n    console.log(results);\n    // [\n    //   { status: "fulfilled", value: 1 },\n    //   { status: "rejected", reason: "error" },\n    //   { status: "fulfilled", value: 3 }\n    // ]\n  });',
followUp: 'How would you implement a `Promise.all` with a concurrency limit?',
keyTakeaway: '`Promise.all` short-circuits on the first rejection while `Promise.allSettled` waits for every Promise to settle.',
  },
  {
id: 61,
title: 'What are `Promise.race()` and `Promise.any()`?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'promises',
answer: '`Promise.race()` returns a Promise that settles as soon as the first input Promise settles, whether it fulfills or rejects. `Promise.any()` returns a Promise that fulfills as soon as the first input Promise fulfills, ignoring rejections. If all Promises passed to `Promise.any()` reject, it rejects with an `AggregateError` containing all rejection reasons. Use `race()` for timeouts or first-response-wins patterns, and `any()` when you want the first successful result from multiple sources.',
codeExample: '// Promise.race — first to settle wins\nconst timeout = new Promise((_, reject) =>\n  setTimeout(() => reject("Timeout"), 3000)\n);\nconst request = fetch("/api/data");\n\nPromise.race([request, timeout])\n  .then((res) => console.log("Got response"))\n  .catch((err) => console.log(err)); // "Timeout" if slow\n\n// Promise.any — first to fulfill wins\nconst fast = Promise.reject("fail");\nconst slow = new Promise((res) => setTimeout(() => res("ok"), 100));\n\nPromise.any([fast, slow])\n  .then((val) => console.log(val)) // "ok"\n  .catch((err) => console.log(err.errors));',
followUp: 'What is an `AggregateError` and when would you encounter one?',
keyTakeaway: '`Promise.race` settles with the first Promise to settle while `Promise.any` fulfills with the first to fulfill.',
  },
  {
id: 62,
title: 'How do you handle errors with `async`/`await`?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'error-handling',
answer: 'The primary way to handle errors with `async`/`await` is using `try`/`catch` blocks, which catch both synchronous throws and rejected Promises. You can also attach `.catch()` directly to an awaited Promise for inline error handling without a full try/catch. For functions that return multiple results, some developers use a tuple pattern inspired by Go, returning `[error, data]` pairs. Unhandled rejections in async functions propagate to the caller, so errors should be caught at appropriate boundaries.',
codeExample: '// try/catch pattern\nasync function fetchUser(id) {\n  try {\n    const res = await fetch(`/api/users/${id}`);\n    if (!res.ok) throw new Error(`HTTP ${res.status}`);\n    return await res.json();\n  } catch (err) {\n    console.error("Fetch failed:", err.message);\n    return null;\n  }\n}\n\n// Inline .catch() pattern\nasync function getConfig() {\n  const config = await fetch("/config")\n    .then((r) => r.json())\n    .catch(() => ({ fallback: true }));\n  return config;\n}\n\n// Tuple pattern\nasync function safeAsync(promise) {\n  try {\n    const data = await promise;\n    return [null, data];\n  } catch (err) {\n    return [err, null];\n  }\n}',
followUp: 'How do you handle errors when running multiple async operations in parallel?',
keyTakeaway: 'Use `try`/`catch` around `await` expressions to handle async errors, mirroring synchronous error handling patterns.',
  },
  {
id: 63,
title: 'What is callback hell and how do Promises solve it?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'callbacks',
answer: 'Callback hell (or the "pyramid of doom") occurs when multiple nested asynchronous callbacks create deeply indented, hard-to-read code. Error handling becomes especially painful because each level needs its own error check. Promises solve this by allowing you to chain `.then()` calls, keeping the code flat and linear. Each `.then()` returns a new Promise, so subsequent operations are chained rather than nested. Combined with `async`/`await`, the code becomes virtually indistinguishable from synchronous code in structure.',
codeExample: '// Callback hell\ngetUser(id, (err, user) => {\n  if (err) return handleError(err);\n  getOrders(user.id, (err, orders) => {\n    if (err) return handleError(err);\n    getItems(orders[0].id, (err, items) => {\n      if (err) return handleError(err);\n      console.log(items);\n    });\n  });\n});\n\n// Flat Promise chain\ngetUser(id)\n  .then((user) => getOrders(user.id))\n  .then((orders) => getItems(orders[0].id))\n  .then((items) => console.log(items))\n  .catch(handleError);\n\n// Even cleaner with async/await\nasync function loadItems(id) {\n  const user = await getUser(id);\n  const orders = await getOrders(user.id);\n  const items = await getItems(orders[0].id);\n  console.log(items);\n}',
followUp: 'Are there cases where callbacks are still preferred over Promises?',
keyTakeaway: 'Callback hell is deeply nested async code that Promises flatten into linear chains and `async`/`await` makes even cleaner.',
  },
  {
id: 64,
title: 'How does `queueMicrotask()` work?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'microtasks',
answer: '`queueMicrotask()` schedules a callback to run in the microtask queue, which is drained after the current synchronous code completes but before any macrotasks execute. It provides a direct way to schedule microtasks without creating a Promise. This is useful for batching DOM updates, ensuring consistent ordering with Promise-based code, or deferring work until after the current execution context finishes. Unlike `setTimeout(fn, 0)` which schedules a macrotask, `queueMicrotask` executes sooner because microtasks have higher priority.',
codeExample: '// queueMicrotask runs before setTimeout\nsetTimeout(() => console.log("timeout"), 0);\n\nqueueMicrotask(() => console.log("microtask 1"));\nqueueMicrotask(() => console.log("microtask 2"));\n\nconsole.log("sync");\n\n// Output:\n// sync\n// microtask 1\n// microtask 2\n// timeout\n\n// Use case: batching updates\nlet pending = false;\nfunction scheduleUpdate() {\n  if (pending) return;\n  pending = true;\n  queueMicrotask(() => {\n    flushUpdates();\n    pending = false;\n  });\n}',
followUp: 'When would you use `queueMicrotask` over `Promise.resolve().then()`?',
keyTakeaway: '`queueMicrotask` directly schedules a microtask that runs after sync code but before any macrotasks like timers.',
  },
  {
id: 65,
title: 'What are `AbortController` and `AbortSignal` used for?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'concurrency',
answer: '`AbortController` provides a mechanism to cancel asynchronous operations like `fetch` requests, event listeners, and streams. It exposes an `AbortSignal` via its `signal` property, which is passed to the async operation. When `controller.abort()` is called, the signal fires an `abort` event and any operation listening to that signal is cancelled. The `fetch` API natively supports `AbortSignal`, rejecting with an `AbortError` when aborted. This is essential for preventing memory leaks and wasted network calls in single-page applications.',
codeExample: 'const controller = new AbortController();\nconst { signal } = controller;\n\n// Cancel a fetch request\nasync function fetchWithTimeout(url, ms) {\n  const controller = new AbortController();\n  const timeoutId = setTimeout(() => controller.abort(), ms);\n\n  try {\n    const res = await fetch(url, { signal: controller.signal });\n    clearTimeout(timeoutId);\n    return await res.json();\n  } catch (err) {\n    if (err.name === "AbortError") {\n      console.log("Request was cancelled");\n    } else {\n      throw err;\n    }\n  }\n}\n\n// AbortSignal.timeout() shorthand\nfetch(url, { signal: AbortSignal.timeout(5000) });',
followUp: 'How would you use `AbortController` to cancel multiple concurrent requests at once?',
keyTakeaway: '`AbortController` lets you cancel in-flight async operations like fetch requests by signaling through an `AbortSignal`.',
  },
  {
id: 66,
title: 'How do Web Workers enable true parallelism?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'concurrency',
answer: 'Web Workers run JavaScript in a separate OS thread, enabling true parallelism rather than the concurrency provided by the event loop. Workers have their own global scope (`self` instead of `window`), their own event loop, and cannot access the DOM. Communication between the main thread and workers happens through `postMessage` and the `message` event, with data being copied via the structured clone algorithm. This makes Workers ideal for CPU-intensive tasks like image processing, data parsing, or complex calculations that would otherwise block the main thread.',
codeExample: '// main.js\nconst worker = new Worker("worker.js");\n\nworker.postMessage({ numbers: [1, 2, 3, 4, 5] });\n\nworker.onmessage = (event) => {\n  console.log("Sum:", event.data.result); // 15\n};\n\nworker.onerror = (err) => {\n  console.error("Worker error:", err.message);\n};\n\n// worker.js\nself.onmessage = (event) => {\n  const { numbers } = event.data;\n  const result = numbers.reduce((a, b) => a + b, 0);\n  self.postMessage({ result });\n};',
followUp: 'What is the difference between a Web Worker and a SharedWorker?',
keyTakeaway: 'Web Workers run in separate threads enabling true parallelism, communicating with the main thread via message passing.',
  },
  {
id: 67,
title: 'What is the difference between parallel and concurrent execution in JavaScript?',
difficulty: 'medium',
topic: 'async-patterns',
subtopic: 'concurrency',
answer: 'Concurrency means multiple tasks make progress over overlapping time periods, but not necessarily at the exact same instant. JavaScript achieves concurrency through the event loop — while one task waits for I/O, another task can execute on the single main thread. Parallelism means multiple tasks execute simultaneously on different threads or CPU cores. In JavaScript, true parallelism is only possible through Web Workers, `worker_threads` in Node.js, or the `Atomics` and `SharedArrayBuffer` APIs. `Promise.all()` provides concurrent execution (interleaved I/O) but not parallel computation on the main thread.',
codeExample: '// Concurrent (not parallel) — single thread\n// Both requests are in-flight simultaneously\n// but JS code executes one piece at a time\nasync function concurrent() {\n  const [users, posts] = await Promise.all([\n    fetch("/api/users").then((r) => r.json()),\n    fetch("/api/posts").then((r) => r.json()),\n  ]);\n  return { users, posts };\n}\n\n// Sequential — one after another\nasync function sequential() {\n  const users = await fetch("/api/users").then((r) => r.json());\n  const posts = await fetch("/api/posts").then((r) => r.json());\n  return { users, posts };\n}\n\n// True parallel — separate threads\n// const worker = new Worker("heavy-calc.js");',
followUp: 'How does `Promise.all` achieve concurrency if JavaScript is single-threaded?',
keyTakeaway: 'Concurrency interleaves tasks on one thread via the event loop while parallelism runs tasks simultaneously on multiple threads.',
  },
  {
id: 68,
title: 'Explain the complete event loop execution order with microtasks, macrotasks, and rendering.',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'event-loop',
answer: 'Each event loop iteration follows this order: (1) execute the current synchronous script or macrotask until the call stack is empty, (2) drain the entire microtask queue including any microtasks enqueued during this phase, (3) if it is time for a rendering update (~16.6ms for 60fps), run `requestAnimationFrame` callbacks, perform style recalculation, layout, and paint, (4) pick the next macrotask from the queue and repeat. The microtask checkpoint happens after every task and every rendering step. This means `requestAnimationFrame` fires before paint but after microtasks, and `setTimeout` callbacks are macrotasks processed one per loop iteration.',
codeExample: 'console.log("1 - script start");\n\nsetTimeout(() => console.log("2 - setTimeout"), 0);\n\nPromise.resolve()\n  .then(() => {\n    console.log("3 - microtask 1");\n    queueMicrotask(() => console.log("4 - nested microtask"));\n  })\n  .then(() => console.log("5 - microtask 2"));\n\nrequestAnimationFrame(() => console.log("6 - rAF"));\n\nconsole.log("7 - script end");\n\n// Output:\n// 1 - script start\n// 7 - script end\n// 3 - microtask 1\n// 4 - nested microtask\n// 5 - microtask 2\n// 6 - rAF (before next paint)\n// 2 - setTimeout',
followUp: 'What happens if a microtask enqueues another microtask indefinitely?',
keyTakeaway: 'The event loop runs: sync code, all microtasks, rendering/rAF if due, then the next macrotask — repeating this cycle.',
  },
  {
id: 69,
title: 'How would you implement a basic Promise from scratch?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'promises',
answer: 'A basic Promise implementation requires maintaining internal state (`pending`, `fulfilled`, `rejected`), a stored value or reason, and arrays of queued handlers. The `resolve` and `reject` functions transition the state and flush queued callbacks. The `.then()` method returns a new Promise, enabling chaining — if the Promise is already settled, callbacks are scheduled asynchronously via `queueMicrotask`; if still pending, they are queued. Error propagation works by catching exceptions in handlers and rejecting the chained Promise. This implementation demonstrates the core of the Promises/A+ specification.',
codeExample: 'class MyPromise {\n  #state = "pending";\n  #value = undefined;\n  #handlers = [];\n\n  constructor(executor) {\n    const resolve = (value) => this.#settle("fulfilled", value);\n    const reject = (reason) => this.#settle("rejected", reason);\n    try {\n      executor(resolve, reject);\n    } catch (err) {\n      reject(err);\n    }\n  }\n\n  #settle(state, value) {\n    if (this.#state !== "pending") return;\n    this.#state = state;\n    this.#value = value;\n    this.#handlers.forEach((h) => this.#execute(h));\n  }\n\n  #execute({ onFulfilled, onRejected, resolve, reject }) {\n    queueMicrotask(() => {\n      const handler = this.#state === "fulfilled"\n        ? onFulfilled : onRejected;\n      try {\n        resolve(handler ? handler(this.#value) : this.#value);\n      } catch (err) {\n        reject(err);\n      }\n    });\n  }\n\n  then(onFulfilled, onRejected) {\n    return new MyPromise((resolve, reject) => {\n      const handler = { onFulfilled, onRejected, resolve, reject };\n      if (this.#state === "pending") {\n        this.#handlers.push(handler);\n      } else {\n        this.#execute(handler);\n      }\n    });\n  }\n\n  catch(onRejected) {\n    return this.then(null, onRejected);\n  }\n}',
followUp: 'How does the Promises/A+ spec handle the case where a `.then` handler returns another Promise?',
keyTakeaway: 'A Promise implementation manages state transitions, queued handlers, and asynchronous resolution to enable chainable async workflows.',
  },
  {
id: 70,
title: 'What is the Structured Clone Algorithm and how does it differ from JSON serialization?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'concurrency',
answer: 'The structured clone algorithm is used by `postMessage`, `structuredClone()`, IndexedDB, and the history API to deep-copy JavaScript values. Unlike `JSON.stringify`/`JSON.parse`, structured clone supports `Map`, `Set`, `Date`, `RegExp`, `ArrayBuffer`, `Blob`, `File`, typed arrays, and circular references. However, it cannot clone functions, DOM nodes, prototype chains, or property descriptors. JSON serialization converts to a string intermediate and loses type information — `Date` becomes a string, `undefined` is omitted, and `NaN`/`Infinity` become `null`. Structured clone preserves types but is not serializable to a string format.',
codeExample: '// JSON serialization loses types\nconst original = {\n  date: new Date(),\n  set: new Set([1, 2, 3]),\n  regex: /hello/gi,\n  undef: undefined,\n  nan: NaN,\n};\n\nconst jsonClone = JSON.parse(JSON.stringify(original));\nconsole.log(jsonClone.date);  // string, not Date\nconsole.log(jsonClone.set);   // {} (empty object)\nconsole.log(jsonClone.regex); // {} (empty object)\nconsole.log(jsonClone.undef); // undefined (key omitted)\nconsole.log(jsonClone.nan);   // null\n\n// structuredClone preserves types\nconst clone = structuredClone(original);\nconsole.log(clone.date instanceof Date);  // true\nconsole.log(clone.set instanceof Set);    // true\nconsole.log(clone.regex instanceof RegExp); // true\nconsole.log(clone.nan);                  // NaN',
followUp: 'What types cannot be cloned by the structured clone algorithm?',
keyTakeaway: 'Structured clone deep-copies objects preserving types like `Date`, `Set`, and `Map` that JSON serialization loses.',
  },
  {
id: 71,
title: 'How do async iterators and `for await...of` work?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'async-await',
answer: 'Async iterators extend the iterator protocol by having their `next()` method return a Promise that resolves to `{ value, done }`. An object is async-iterable if it implements `Symbol.asyncIterator`. The `for await...of` loop consumes async iterables, awaiting each value before proceeding to the next iteration. This is particularly useful for streaming data — reading lines from a file, consuming paginated API results, or processing server-sent events. Async generators (`async function*`) provide a convenient way to create async iterators using `yield` within an async context.',
codeExample: '// Async generator function\nasync function* fetchPages(url) {\n  let page = 1;\n  let hasMore = true;\n  while (hasMore) {\n    const res = await fetch(`${url}?page=${page}`);\n    const data = await res.json();\n    yield data.items;\n    hasMore = data.hasNextPage;\n    page++;\n  }\n}\n\n// Consuming with for await...of\nasync function getAllItems() {\n  const allItems = [];\n  for await (const items of fetchPages("/api/products")) {\n    allItems.push(...items);\n  }\n  return allItems;\n}\n\n// Custom async iterable\nconst asyncRange = {\n  [Symbol.asyncIterator]() {\n    let i = 0;\n    return {\n      next() {\n        if (i < 3) {\n          return Promise.resolve({ value: i++, done: false });\n        }\n        return Promise.resolve({ done: true });\n      },\n    };\n  },\n};',
followUp: 'How do async iterators interact with backpressure in streams?',
keyTakeaway: 'Async iterators yield Promises that `for await...of` consumes sequentially, ideal for streaming and paginated data.',
  },
  {
id: 72,
title: 'What are race conditions in JavaScript and how do you prevent them?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'concurrency',
answer: 'Race conditions occur when the outcome of a program depends on the unpredictable timing of asynchronous operations. In JavaScript, a common example is when a user triggers multiple API calls and a stale response arrives after a newer one, overwriting the correct state. Unlike multi-threaded race conditions, JavaScript race conditions stem from non-deterministic async completion order. Prevention strategies include using `AbortController` to cancel outdated requests, tracking request IDs or timestamps to discard stale responses, using mutex/semaphore patterns for critical sections, and structuring state updates to only accept the most recent result.',
codeExample: '// Race condition: stale response overwrites fresh\nlet latestQuery = "";\nasync function searchBroken(query) {\n  latestQuery = query;\n  const res = await fetch(`/api/search?q=${query}`);\n  const data = await res.json();\n  // Bug: if "ab" resolves after "abc", it overwrites\n  setResults(data);\n}\n\n// Fix 1: Track latest request\nasync function searchFixed(query) {\n  latestQuery = query;\n  const res = await fetch(`/api/search?q=${query}`);\n  const data = await res.json();\n  if (query === latestQuery) {\n    setResults(data); // Only update if still relevant\n  }\n}\n\n// Fix 2: AbortController\nlet controller = null;\nasync function searchAbortable(query) {\n  controller?.abort();\n  controller = new AbortController();\n  try {\n    const res = await fetch(`/api/search?q=${query}`, {\n      signal: controller.signal,\n    });\n    setResults(await res.json());\n  } catch (err) {\n    if (err.name !== "AbortError") throw err;\n  }\n}',
followUp: 'How does React 18 handle race conditions with its `useEffect` cleanup pattern?',
keyTakeaway: 'JavaScript race conditions arise from non-deterministic async timing and are prevented with abort controllers or request tracking.',
  },
  {
id: 73,
title: 'How does `requestAnimationFrame` differ from `setTimeout` for animations?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'event-loop',
answer: '`requestAnimationFrame` (rAF) schedules a callback to run before the browser performs its next repaint, typically at 60fps (every ~16.6ms). Unlike `setTimeout`, rAF automatically pauses when the tab is inactive (saving CPU and battery), syncs with the display refresh rate to avoid tearing and jank, and provides a high-resolution timestamp for frame-accurate calculations. `setTimeout`-based animations can drift, run unnecessarily in background tabs, and fire at inconsistent intervals that do not align with paint cycles. rAF callbacks run during the rendering phase of the event loop, after microtasks and before paint.',
codeExample: '// setTimeout animation — can jank and drifts\nfunction animateTimeout(element) {\n  let pos = 0;\n  function step() {\n    pos += 2;\n    element.style.transform = `translateX(${pos}px)`;\n    if (pos < 300) {\n      setTimeout(step, 16); // Approximate 60fps\n    }\n  }\n  step();\n}\n\n// requestAnimationFrame — smooth and synced\nfunction animateRAF(element) {\n  let start = null;\n  function step(timestamp) {\n    if (!start) start = timestamp;\n    const elapsed = timestamp - start;\n    const pos = Math.min(elapsed * 0.2, 300);\n    element.style.transform = `translateX(${pos}px)`;\n    if (pos < 300) {\n      requestAnimationFrame(step);\n    }\n  }\n  requestAnimationFrame(step);\n}\n\n// Cancel with cancelAnimationFrame\nconst id = requestAnimationFrame(callback);\ncancelAnimationFrame(id);',
followUp: 'How would you implement a frame-rate-independent animation using `requestAnimationFrame`?',
keyTakeaway: '`requestAnimationFrame` syncs with the display refresh rate and pauses in background tabs, making it superior to `setTimeout` for animations.',
  },
  {
id: 74,
title: 'What is top-level `await` and what are its implications?',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'async-await',
answer: 'Top-level `await` allows you to use the `await` keyword at the module level without wrapping it in an async function. It is only available in ES modules (not CommonJS). When a module uses top-level `await`, it pauses its own execution and any modules that depend on it until the awaited Promise resolves. This means importing a module with top-level `await` is inherently asynchronous and can delay the entire dependency graph. It is useful for dynamic imports, conditional module loading, and initialization that requires async setup, but should be used sparingly to avoid blocking module graph execution.',
codeExample: '// config.mjs — top-level await\nconst response = await fetch("/api/config");\nexport const config = await response.json();\n\n// db.mjs — conditional initialization\nlet db;\nif (process.env.NODE_ENV === "production") {\n  db = await import("./prod-db.mjs");\n} else {\n  db = await import("./dev-db.mjs");\n}\nexport { db };\n\n// main.mjs — importing blocks until config resolves\nimport { config } from "./config.mjs";\nimport { db } from "./db.mjs";\n\n// Both config and db are fully resolved here\nconsole.log(config.apiUrl);\nconsole.log(db.connection);\n\n// Fallback pattern\nlet translations;\ntry {\n  translations = await import(`./i18n/${lang}.mjs`);\n} catch {\n  translations = await import("./i18n/en.mjs");\n}',
followUp: 'How does top-level `await` affect module loading order in a complex dependency graph?',
keyTakeaway: 'Top-level `await` lets modules pause execution during load, blocking dependents until the async operation completes.',
  },
  {
id: 75,
title: 'Implement throttle and debounce functions.',
difficulty: 'hard',
topic: 'async-patterns',
subtopic: 'timers',
answer: 'Throttle limits a function to execute at most once per specified time interval, ensuring regular execution during sustained events like scrolling. Debounce delays execution until a specified period of inactivity has passed, resetting the timer with each new invocation — ideal for search-as-you-type inputs. The key difference is timing: throttle guarantees execution at regular intervals during activity, while debounce only fires after activity stops. Both are essential for performance optimization, preventing excessive API calls, layout recalculations, or expensive computations during rapid user interactions.',
codeExample: '// Throttle — at most once per interval\nfunction throttle(fn, ms) {\n  let lastCall = 0;\n  let timeoutId = null;\n  return function (...args) {\n    const now = Date.now();\n    const remaining = ms - (now - lastCall);\n    clearTimeout(timeoutId);\n    if (remaining <= 0) {\n      lastCall = now;\n      fn.apply(this, args);\n    } else {\n      timeoutId = setTimeout(() => {\n        lastCall = Date.now();\n        fn.apply(this, args);\n      }, remaining);\n    }\n  };\n}\n\n// Debounce — fires after inactivity\nfunction debounce(fn, ms) {\n  let timeoutId = null;\n  return function (...args) {\n    clearTimeout(timeoutId);\n    timeoutId = setTimeout(() => {\n      fn.apply(this, args);\n    }, ms);\n  };\n}\n\n// Usage\nwindow.addEventListener("scroll", throttle(handleScroll, 200));\nsearchInput.addEventListener("input", debounce(search, 300));',
followUp: 'How would you add a leading/trailing option to throttle and a cancel method to debounce?',
keyTakeaway: 'Throttle caps execution frequency during activity while debounce waits for a pause in activity before firing.',
  },
{
  id: 76,
  title: 'What are ES6 modules and how do `import`/`export` work?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'modules',
  answer: 'ES6 modules are the native JavaScript module system introduced in ES2015. You use `export` to expose bindings from a module and `import` to consume them in another file. There are two kinds of exports: named exports, where you export specific bindings by name and import them with curly braces, and default exports, where you export a single primary value that can be imported with any name. ES modules are statically analyzable, meaning the engine knows the dependency graph at parse time before any code runs. They also run in strict mode by default and have their own scope, preventing global namespace pollution.',
  codeExample: '// math.js — named exports\nexport const PI = 3.14159\nexport function add(a, b) {\n  return a + b\n}\n\n// logger.js — default export\nexport default function log(msg) {\n  console.log(`[LOG] ${msg}`)\n}\n\n// app.js — importing\nimport { PI, add } from \'./math.js\'\nimport log from \'./logger.js\'\nimport { add as sum } from \'./math.js\' // renaming\nimport * as math from \'./math.js\' // namespace import\n\nconsole.log(math.PI) // 3.14159\nlog(sum(2, 3))       // [LOG] 5',
  followUp: 'What happens if you try to reassign a named import binding?',
  keyTakeaway: 'ES modules use static `import`/`export` syntax for named and default bindings, enabling tree shaking and strict scoping.',
},
{
  id: 77,
  title: 'What is the `Map` data structure and how does it differ from plain objects?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'map-set',
  answer: '`Map` is a built-in collection that stores key-value pairs where keys can be any type, including objects, functions, and primitives. Unlike plain objects, which coerce all keys to strings, `Map` preserves the original type and identity of keys. `Map` also maintains insertion order when iterating, has a `.size` property for O(1) length access, and provides convenient methods like `set()`, `get()`, `has()`, and `delete()`. Performance-wise, `Map` is optimized for frequent additions and deletions of key-value pairs, while plain objects are better suited for static shapes with known string keys.',
  codeExample: 'const map = new Map()\n\n// Any type can be a key\nconst objKey = { id: 1 }\nconst fnKey = () => {}\n\nmap.set(objKey, \'object value\')\nmap.set(fnKey, \'function value\')\nmap.set(42, \'number value\')\n\nconsole.log(map.get(objKey)) // \'object value\'\nconsole.log(map.has(42))     // true\nconsole.log(map.size)        // 3\n\n// Iteration preserves insertion order\nfor (const [key, value] of map) {\n  console.log(key, value)\n}\n\n// Convert to array of entries\nconst entries = [...map] // [[objKey, \'object value\'], ...]',
  followUp: 'When would you choose a plain object over a `Map`?',
  keyTakeaway: '`Map` supports any key type, preserves insertion order, and is optimized for frequent additions and deletions unlike plain objects.',
},
{
  id: 78,
  title: 'What is the `Set` data structure?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'map-set',
  answer: '`Set` is a built-in collection that stores unique values of any type. If you attempt to add a duplicate value, it is silently ignored — `Set` uses the SameValueZero algorithm for equality, which treats `NaN` as equal to itself (unlike `===`). `Set` maintains insertion order, provides O(1) lookup with `has()`, and offers methods like `add()`, `delete()`, and `clear()`. Common use cases include deduplicating arrays, tracking visited items, and performing set operations like union, intersection, and difference.',
  codeExample: 'const set = new Set([1, 2, 3, 2, 1])\nconsole.log(set.size) // 3\nconsole.log([...set]) // [1, 2, 3]\n\nset.add(4)\nset.has(3)    // true\nset.delete(2) // removes 2\n\n// Deduplicate an array\nconst arr = [1, 1, 2, 3, 3, 4]\nconst unique = [...new Set(arr)] // [1, 2, 3, 4]\n\n// NaN equality\nconst s = new Set()\ns.add(NaN)\ns.add(NaN)\nconsole.log(s.size) // 1 — NaN equals NaN in Set\n\n// Set operations (ES2025 methods)\nconst a = new Set([1, 2, 3])\nconst b = new Set([2, 3, 4])\nconsole.log(a.intersection(b)) // Set {2, 3}\nconsole.log(a.union(b))        // Set {1, 2, 3, 4}',
  followUp: 'How does `Set` determine equality for objects?',
  keyTakeaway: '`Set` stores unique values of any type, uses SameValueZero equality, and is ideal for deduplication and membership checks.',
},
{
  id: 79,
  title: 'What are `Array.from()` and `Array.of()`?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: '`Array.from()` creates a new array from any iterable or array-like object (anything with a `length` property and indexed elements). It accepts an optional mapping function as a second argument, making it a concise way to generate and transform arrays in one step. `Array.of()` creates a new array from its arguments, solving the inconsistency of the `Array()` constructor where `Array(3)` creates an empty array with length 3 instead of `[3]`. Together, these static methods provide clean, predictable ways to create arrays without constructor ambiguity.',
  codeExample: '// Array.from — convert iterables and array-likes\nArray.from(\'hello\')         // [\'h\', \'e\', \'l\', \'l\', \'o\']\nArray.from(new Set([1, 2])) // [1, 2]\nArray.from({ length: 3 })   // [undefined, undefined, undefined]\n\n// With mapping function (second argument)\nArray.from({ length: 5 }, (_, i) => i * 2)\n// [0, 2, 4, 6, 8]\n\n// Convert NodeList to array\nconst divs = Array.from(document.querySelectorAll(\'div\'))\n\n// Array.of — predictable array creation\nArray.of(3)       // [3]       (not an empty array of length 3)\nArray.of(1, 2, 3) // [1, 2, 3]\n\n// Compare with Array constructor\nnew Array(3)       // [ , , ] — sparse array with length 3\nnew Array(1, 2, 3) // [1, 2, 3]',
  followUp: 'What is the difference between `Array.from()` and the spread operator for converting iterables?',
  keyTakeaway: '`Array.from()` converts iterables and array-likes to arrays with optional mapping, while `Array.of()` fixes the ambiguous `Array()` constructor behavior.',
},
{
  id: 80,
  title: 'What are computed property names in object literals?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'Computed property names allow you to use an expression inside square brackets as a property key when defining an object literal. The expression is evaluated at runtime, and the result becomes the property name. This eliminates the need to create an object first and then add dynamic keys with bracket notation in a separate statement. Computed properties are commonly used with variables, template literals, `Symbol` values, and function return values as keys.',
  codeExample: 'const field = \'name\'\nconst index = 42\n\n// Computed property names\nconst obj = {\n  [field]: \'Alice\',\n  [`user_${index}`]: true,\n  [Symbol.iterator]: function* () {\n    yield 1\n  },\n}\n\nconsole.log(obj.name)     // \'Alice\'\nconsole.log(obj.user_42)  // true\n\n// Dynamic state updates (common in React)\nfunction updateField(state, key, value) {\n  return { ...state, [key]: value }\n}\n\nconst state = { name: \'Alice\', age: 30 }\nupdateField(state, \'age\', 31)\n// { name: \'Alice\', age: 31 }',
  followUp: 'Can you use computed property names with destructuring?',
  keyTakeaway: 'Computed property names use square brackets in object literals to evaluate expressions as keys at runtime.',
},
{
  id: 81,
  title: 'What is the `for...of` loop and what is the iterable protocol?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'iterators',
  answer: 'The `for...of` loop iterates over the values of any iterable object — arrays, strings, `Map`, `Set`, `NodeList`, `TypedArray`, and any custom object implementing the iterable protocol. An object is iterable if it has a `[Symbol.iterator]()` method that returns an iterator object with a `next()` method. Unlike `for...in`, which iterates over enumerable property keys (including inherited ones), `for...of` iterates over values and works only with objects that implement the iterable protocol. You can also use `break`, `continue`, and `return` inside `for...of` to control flow.',
  codeExample: '// for...of with various iterables\nfor (const char of \'hello\') {\n  console.log(char) // \'h\', \'e\', \'l\', \'l\', \'o\'\n}\n\nconst map = new Map([[\'a\', 1], [\'b\', 2]])\nfor (const [key, value] of map) {\n  console.log(key, value) // \'a\' 1, \'b\' 2\n}\n\n// Custom iterable\nconst range = {\n  from: 1,\n  to: 3,\n  [Symbol.iterator]() {\n    let current = this.from\n    const last = this.to\n    return {\n      next() {\n        return current <= last\n          ? { value: current++, done: false }\n          : { done: true }\n      },\n    }\n  },\n}\n\nfor (const n of range) {\n  console.log(n) // 1, 2, 3\n}',
  followUp: 'Can you use `for...of` with plain objects, and if not, how would you make an object iterable?',
  keyTakeaway: '`for...of` iterates over values of iterable objects that implement a `[Symbol.iterator]()` method returning a `next()`-based iterator.',
},
{
  id: 82,
  title: 'What is object shorthand property and method syntax?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'ES6 introduced shorthand syntax for object literals that reduces boilerplate. When a property name matches a variable name, you can omit the colon and value — `{ name }` instead of `{ name: name }`. For methods, you can omit the `function` keyword and colon — `{ greet() {} }` instead of `{ greet: function() {} }`. Shorthand methods also support `async`, generator (`*`), computed names, and getter/setter syntax. This shorthand is purely syntactic sugar and produces identical objects, but it makes code more concise and is the idiomatic style in modern JavaScript.',
  codeExample: 'const name = \'Alice\'\nconst age = 30\n\n// Shorthand properties\nconst user = { name, age }\n// Equivalent to: { name: \'Alice\', age: 30 }\n\n// Shorthand methods\nconst service = {\n  users: [],\n  add(user) {\n    this.users.push(user)\n  },\n  async fetchAll() {\n    return await fetch(\'/api/users\')\n  },\n  *ids() {\n    for (const u of this.users) yield u.id\n  },\n  get count() {\n    return this.users.length\n  },\n}\n\n// Combining with destructuring\nfunction createPoint(x, y) {\n  return { x, y, toString() { return `(${x}, ${y})` } }\n}',
  followUp: 'Is there any difference in `this` binding between shorthand methods and arrow functions on objects?',
  keyTakeaway: 'Shorthand properties omit redundant key-value repetition, and shorthand methods omit the `function` keyword for cleaner object literals.',
},
{
  id: 83,
  title: 'What are the different error types in JavaScript?',
  difficulty: 'easy',
  topic: 'modern-js',
  subtopic: 'error-handling',
  answer: 'JavaScript has several built-in error types that all inherit from the base `Error` class. `TypeError` is thrown when an operation is performed on a value of the wrong type, such as calling a non-function. `ReferenceError` occurs when referencing an undeclared variable. `SyntaxError` is thrown during parsing when code violates grammar rules. `RangeError` happens when a value is outside an allowed range, like passing a negative length to `Array()`. `URIError` occurs from malformed URI functions, and `EvalError` is retained for backward compatibility. You can also create custom error classes by extending `Error` for domain-specific error handling.',
  codeExample: '// TypeError — wrong type operation\ntry {\n  null.toString()\n} catch (e) {\n  console.log(e instanceof TypeError) // true\n}\n\n// ReferenceError — undeclared variable\ntry {\n  console.log(undeclaredVar)\n} catch (e) {\n  console.log(e.name) // \'ReferenceError\'\n}\n\n// RangeError — value out of range\ntry {\n  new Array(-1)\n} catch (e) {\n  console.log(e.name) // \'RangeError\'\n}\n\n// Custom error class\nclass ValidationError extends Error {\n  constructor(field, message) {\n    super(message)\n    this.name = \'ValidationError\'\n    this.field = field\n  }\n}\n\nthrow new ValidationError(\'email\', \'Invalid format\')',
  followUp: 'How does the `cause` property in `Error` options work for error chaining?',
  keyTakeaway: 'JavaScript has built-in error types like `TypeError`, `ReferenceError`, and `SyntaxError` that all extend the base `Error` class.',
},
{
  id: 84,
  title: 'What are `WeakMap` and `WeakSet` and why are they useful?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'collections',
  answer: '`WeakMap` and `WeakSet` are collections that hold weak references to their keys (for `WeakMap`) or values (for `WeakSet`), meaning they do not prevent garbage collection. If no other reference to an object exists, the garbage collector can reclaim it even though it is still in a `WeakMap` or `WeakSet`. Keys in `WeakMap` and values in `WeakSet` must be objects or non-registered symbols — primitives are not allowed. Because entries can disappear at any time, these collections are not iterable and have no `size` property. They are ideal for associating metadata with objects without causing memory leaks, such as caching computed results, tracking DOM nodes, or storing private data.',
  codeExample: '// WeakMap — associate data with objects\nconst metadata = new WeakMap()\n\nfunction process(obj) {\n  if (metadata.has(obj)) return metadata.get(obj)\n  const result = { processed: true, timestamp: Date.now() }\n  metadata.set(obj, result)\n  return result\n}\n\nlet user = { name: \'Alice\' }\nprocess(user)\n\nuser = null // user object can be garbage collected\n// WeakMap entry is automatically cleaned up\n\n// WeakSet — track objects without preventing GC\nconst visited = new WeakSet()\n\nfunction visit(node) {\n  if (visited.has(node)) return // already visited\n  visited.add(node)\n  // process node...\n}\n\n// Private data pattern\nconst privateData = new WeakMap()\nclass Person {\n  constructor(name, ssn) {\n    this.name = name\n    privateData.set(this, { ssn })\n  }\n  getSSN() {\n    return privateData.get(this).ssn\n  }\n}',
  followUp: 'Why can you not iterate over a `WeakMap` or `WeakSet`?',
  keyTakeaway: '`WeakMap` and `WeakSet` hold weak references that allow garbage collection, preventing memory leaks when associating data with objects.',
},
{
  id: 85,
  title: 'What are iterators and the iterator protocol?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'iterators',
  answer: 'The iterator protocol defines a standard way to produce a sequence of values. An object is an iterator if it has a `next()` method that returns an object with two properties: `value` (the current element) and `done` (a boolean indicating whether the sequence is exhausted). When `done` is `true`, the iteration is complete. An iterable is any object with a `[Symbol.iterator]()` method that returns an iterator. Built-in iterables like arrays, strings, and `Map` all implement this protocol. The iterator protocol is consumed by `for...of`, spread syntax, destructuring, `Array.from()`, `Promise.all()`, and other language features.',
  codeExample: '// Manual iterator\nfunction createCounter(start, end) {\n  let current = start\n  return {\n    next() {\n      if (current <= end) {\n        return { value: current++, done: false }\n      }\n      return { value: undefined, done: true }\n    },\n  }\n}\n\nconst counter = createCounter(1, 3)\nconsole.log(counter.next()) // { value: 1, done: false }\nconsole.log(counter.next()) // { value: 2, done: false }\nconsole.log(counter.next()) // { value: 3, done: false }\nconsole.log(counter.next()) // { value: undefined, done: true }\n\n// Making an object both iterable and iterator\nclass Range {\n  constructor(start, end) {\n    this.start = start\n    this.end = end\n  }\n  [Symbol.iterator]() {\n    let current = this.start\n    const end = this.end\n    return {\n      next() {\n        return current <= end\n          ? { value: current++, done: false }\n          : { done: true }\n      },\n      [Symbol.iterator]() { return this },\n    }\n  }\n}\n\nconst range = new Range(1, 5)\nconsole.log([...range]) // [1, 2, 3, 4, 5]',
  followUp: 'What is the `return()` method on iterators and when is it called?',
  keyTakeaway: 'Iterators implement a `next()` method returning `{ value, done }` objects, and iterables provide a `[Symbol.iterator]()` that returns an iterator.',
},
{
  id: 86,
  title: 'What are dynamic imports and when would you use them?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'modules',
  answer: 'Dynamic imports use the `import()` function syntax to load modules asynchronously at runtime, returning a promise that resolves to the module namespace object. Unlike static `import` declarations that must appear at the top level, `import()` can be used anywhere — inside functions, conditionals, event handlers, or loops. This enables code splitting, where you load modules only when needed rather than upfront, reducing initial bundle size. Common use cases include route-based splitting in SPAs, loading heavy libraries on demand (like a chart library when a user opens a dashboard), conditionally loading polyfills, and lazy-loading components.',
  codeExample: '// Basic dynamic import\nasync function loadChart() {\n  const { Chart } = await import(\'./chart.js\')\n  return new Chart(\'#canvas\')\n}\n\n// Conditional loading\nasync function initEditor(type) {\n  if (type === \'markdown\') {\n    const { MarkdownEditor } = await import(\'./MarkdownEditor.js\')\n    return new MarkdownEditor()\n  }\n  const { RichTextEditor } = await import(\'./RichTextEditor.js\')\n  return new RichTextEditor()\n}\n\n// Route-based code splitting\nconst routes = {\n  \'/dashboard\': () => import(\'./pages/Dashboard.js\'),\n  \'/settings\': () => import(\'./pages/Settings.js\'),\n}\n\nasync function navigate(path) {\n  const module = await routes[path]()\n  module.default.render()\n}\n\n// With error handling\ntry {\n  const mod = await import(\'./optional-feature.js\')\n  mod.init()\n} catch (err) {\n  console.warn(\'Feature not available\')\n}',
  followUp: 'How do bundlers like Webpack and Vite handle `import()` for code splitting?',
  keyTakeaway: 'Dynamic `import()` loads modules asynchronously at runtime, enabling code splitting and on-demand loading to reduce initial bundle size.',
},
{
  id: 87,
  title: 'What is the difference between deep copy and shallow copy?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'A shallow copy creates a new object and copies the top-level properties, but nested objects and arrays are still shared by reference with the original. Modifying a nested property on the copy will also mutate the original. A deep copy recursively duplicates every level of nesting, producing a completely independent clone where no references are shared. The spread operator and `Object.assign()` perform shallow copies. For deep copies, `structuredClone()` is the modern standard, while `JSON.parse(JSON.stringify())` works for JSON-safe data but fails on `undefined`, functions, `Date`, `Map`, `Set`, and circular references.',
  codeExample: '// Shallow copy — nested objects are shared\nconst original = {\n  name: \'Alice\',\n  address: { city: \'NYC\' },\n  scores: [90, 85],\n}\n\nconst shallow = { ...original }\nshallow.name = \'Bob\'         // does NOT affect original\nshallow.address.city = \'LA\'  // MUTATES original.address!\nconsole.log(original.address.city) // \'LA\'\n\n// Deep copy with structuredClone\nconst deep = structuredClone(original)\ndeep.address.city = \'Chicago\'\nconsole.log(original.address.city) // \'LA\' (unchanged)\n\n// JSON trick (limited — loses functions, dates, etc.)\nconst jsonClone = JSON.parse(JSON.stringify(original))\n\n// structuredClone handles things JSON cannot\nconst complex = {\n  date: new Date(),\n  data: new Map([[\'key\', \'value\']]),\n  buffer: new ArrayBuffer(8),\n}\nconst cloned = structuredClone(complex)\nconsole.log(cloned.date instanceof Date) // true\nconsole.log(cloned.data instanceof Map)  // true',
  followUp: 'What types of values cannot be cloned by `structuredClone()`?',
  keyTakeaway: 'Shallow copy duplicates top-level properties but shares nested references, while deep copy recursively clones all levels for full independence.',
},
{
  id: 88,
  title: 'What is the `structuredClone()` function?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: '`structuredClone()` is a global function that creates a deep copy of a value using the structured clone algorithm. It handles complex types that `JSON.parse(JSON.stringify())` cannot, including `Date`, `RegExp`, `Map`, `Set`, `ArrayBuffer`, `Blob`, `File`, `ImageData`, and even circular references. It works in all modern browsers, Node.js 17+, and Deno. However, it cannot clone functions, DOM nodes, `Error` objects, property descriptors, or prototype chains — attempting to clone these throws a `DataCloneError`. It is now the recommended approach for deep cloning in JavaScript.',
  codeExample: '// Basic deep clone\nconst original = {\n  name: \'Alice\',\n  tags: new Set([\'admin\', \'user\']),\n  metadata: new Map([[\'created\', new Date()]]),\n  nested: { deep: { value: 42 } },\n}\n\nconst clone = structuredClone(original)\nclone.nested.deep.value = 99\nconsole.log(original.nested.deep.value) // 42 (unaffected)\nconsole.log(clone.tags instanceof Set)  // true\n\n// Handles circular references\nconst circular = { name: \'self\' }\ncircular.self = circular\nconst cloned = structuredClone(circular)\nconsole.log(cloned.self === cloned) // true (new circular ref)\n\n// Transfer buffers (zero-copy move)\nconst buffer = new ArrayBuffer(1024)\nconst transferred = structuredClone(buffer, {\n  transfer: [buffer],\n})\nconsole.log(buffer.byteLength)      // 0 (transferred away)\nconsole.log(transferred.byteLength) // 1024',
  followUp: 'What is the `transfer` option in `structuredClone()` and when would you use it?',
  keyTakeaway: '`structuredClone()` deep-clones values including `Date`, `Map`, `Set`, and circular references, replacing the `JSON.parse(JSON.stringify())` workaround.',
},
{
  id: 89,
  title: 'How do ES modules differ from CommonJS modules?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'modules',
  answer: 'ES modules (ESM) use `import`/`export` syntax and are statically analyzed at parse time, while CommonJS (CJS) uses `require()`/`module.exports` and is evaluated dynamically at runtime. ESM exports are live bindings — importing modules see updates when the exporting module changes a value — whereas CJS exports are copied values. ESM runs in strict mode by default and has asynchronous loading semantics, making it suitable for both browsers and servers. CJS loads synchronously, which is fine for Node.js filesystem-based loading but not for browsers. The static nature of ESM enables tree shaking, where bundlers can eliminate unused exports at build time.',
  codeExample: '// ===== ES Modules =====\n// counter.mjs\nexport let count = 0\nexport function increment() { count++ }\n\n// app.mjs\nimport { count, increment } from \'./counter.mjs\'\nconsole.log(count) // 0\nincrement()\nconsole.log(count) // 1 (live binding!)\n\n// ===== CommonJS =====\n// counter.cjs\nlet count = 0\nmodule.exports = {\n  count,\n  increment() { count++ },\n}\n\n// app.cjs\nconst counter = require(\'./counter.cjs\')\nconsole.log(counter.count) // 0\ncounter.increment()\nconsole.log(counter.count) // 0 (copied value, NOT live)\n\n// Key differences summary:\n// ESM: static, async, live bindings, tree-shakable\n// CJS: dynamic, sync, copied values, no tree shaking',
  followUp: 'Can you use `require()` inside an ES module, and how do you handle interoperability?',
  keyTakeaway: 'ESM uses static `import`/`export` with live bindings and tree shaking support, while CJS uses dynamic `require()` with copied values.',
},
{
  id: 90,
  title: 'What is the Observer pattern and how is it used in JavaScript?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'The Observer pattern defines a one-to-many dependency where one object (the subject or observable) maintains a list of dependents (observers) and automatically notifies them of state changes. In JavaScript, this pattern appears in DOM event listeners, the `MutationObserver`, `IntersectionObserver`, `ResizeObserver`, and `PerformanceObserver` browser APIs. It is also the foundation of reactive libraries like RxJS. The pattern decouples the producer of events from the consumers, allowing multiple independent components to react to the same change without the subject knowing the specifics of its observers.',
  codeExample: '// Simple Observer implementation\nclass Observable {\n  constructor() {\n    this.observers = new Map()\n  }\n  subscribe(event, fn) {\n    if (!this.observers.has(event)) {\n      this.observers.set(event, new Set())\n    }\n    this.observers.get(event).add(fn)\n    return () => this.observers.get(event).delete(fn)\n  }\n  notify(event, data) {\n    const subs = this.observers.get(event)\n    if (subs) subs.forEach(fn => fn(data))\n  }\n}\n\nconst store = new Observable()\nconst unsub = store.subscribe(\'update\', (data) => {\n  console.log(\'State changed:\', data)\n})\n\nstore.notify(\'update\', { count: 1 })\nunsub() // unsubscribe\n\n// Built-in browser Observer APIs\nconst observer = new IntersectionObserver((entries) => {\n  entries.forEach(entry => {\n    if (entry.isIntersecting) {\n      entry.target.classList.add(\'visible\')\n    }\n  })\n})\nobserver.observe(document.querySelector(\'.lazy\'))',
  followUp: 'What is the difference between the Observer pattern and the Pub/Sub pattern?',
  keyTakeaway: 'The Observer pattern lets a subject notify multiple observers of state changes, decoupling event producers from consumers.',
},
{
  id: 91,
  title: 'How does tree shaking work with ES modules?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'modules',
  answer: 'Tree shaking is a dead-code elimination technique where bundlers analyze the static import/export graph of ES modules to remove unused exports from the final bundle. Because ESM `import` and `export` declarations are statically analyzable (they cannot be conditional or dynamic), the bundler can determine at build time which exports are actually consumed and safely discard the rest. This only works with named exports — default exports and CommonJS `require()` are harder to analyze. Side effects in modules can prevent tree shaking, which is why `package.json` has a `"sideEffects"` field to tell bundlers which files are safe to prune.',
  codeExample: '// utils.js — module with multiple exports\nexport function add(a, b) { return a + b }\nexport function subtract(a, b) { return a - b }\nexport function multiply(a, b) { return a * b }\nexport function divide(a, b) { return a / b }\n\n// app.js — only imports add\nimport { add } from \'./utils.js\'\nconsole.log(add(2, 3))\n\n// After tree shaking, subtract, multiply, divide\n// are removed from the bundle entirely\n\n// package.json — declare side-effect-free files\n// {\n//   "sideEffects": false\n// }\n// Or specify files with side effects:\n// {\n//   "sideEffects": ["./src/polyfills.js", "*.css"]\n// }\n\n// BAD for tree shaking — barrel re-exports\n// index.js\nexport * from \'./heavyModule.js\' // pulls everything in\n\n// GOOD — direct imports\nimport { specificFn } from \'./heavyModule.js\'',
  followUp: 'Why do barrel files (index.js re-exports) sometimes defeat tree shaking?',
  keyTakeaway: 'Tree shaking uses the static import/export graph of ESM to eliminate unused code from bundles, reducing payload size.',
},
{
  id: 92,
  title: 'What are the different ways to handle errors in JavaScript?',
  difficulty: 'medium',
  topic: 'modern-js',
  subtopic: 'error-handling',
  answer: '`try/catch/finally` is the synchronous error handling mechanism — `catch` receives thrown errors and `finally` always runs regardless of outcome. For promises, you can use `.catch()` in promise chains or `try/catch` with `async/await`. Global unhandled errors can be caught with `window.onerror` or the `error` event in browsers and `process.on(\'uncaughtException\')` in Node.js. Unhandled promise rejections are caught with `unhandledrejection` events or `process.on(\'unhandledRejection\')`. The `Error` `cause` option (ES2022) enables error chaining to preserve the original error context when rethrowing.',
  codeExample: '// try/catch/finally\ntry {\n  JSON.parse(\'invalid json\')\n} catch (error) {\n  console.error(error.message)\n} finally {\n  console.log(\'Always runs\')\n}\n\n// Async/await error handling\nasync function fetchUser(id) {\n  try {\n    const res = await fetch(`/api/users/${id}`)\n    if (!res.ok) throw new Error(`HTTP ${res.status}`)\n    return await res.json()\n  } catch (error) {\n    throw new Error(\'Failed to fetch user\', { cause: error })\n  }\n}\n\n// Promise chain error handling\nfetch(\'/api/data\')\n  .then(res => res.json())\n  .catch(err => console.error(\'Fetch failed:\', err))\n\n// Global handlers\nwindow.addEventListener(\'unhandledrejection\', (event) => {\n  console.error(\'Unhandled rejection:\', event.reason)\n  event.preventDefault()\n})\n\n// Error cause chain\ntry {\n  await fetchUser(999)\n} catch (err) {\n  console.log(err.message)       // \'Failed to fetch user\'\n  console.log(err.cause.message) // \'HTTP 404\'\n}',
  followUp: 'What is the difference between operational errors and programmer errors, and how should each be handled?',
  keyTakeaway: 'JavaScript offers `try/catch` for sync code, `.catch()`/`try-await-catch` for async, and global handlers for uncaught errors and rejections.',
},
{
  id: 93,
  title: 'What is the Proxy trap pattern and how do you use it for validation?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'proxy',
  answer: '`Proxy` wraps a target object and intercepts fundamental operations via handler traps — methods like `get`, `set`, `has`, `deleteProperty`, `apply`, and `construct`. The `set` trap is particularly useful for validation: it receives the target, property name, new value, and the proxy receiver, and must return `true` if the assignment should succeed or `false` (which throws a `TypeError` in strict mode) to reject it. You can use `Reflect` methods inside traps to perform the default behavior after your custom logic. Proxies are powerful for building reactive systems, implementing access control, auto-populating default values, and creating type-safe data layers without modifying the underlying objects.',
  codeExample: '// Validation proxy\nconst userValidator = {\n  set(target, prop, value) {\n    if (prop === \'age\') {\n      if (typeof value !== \'number\' || value < 0 || value > 150) {\n        throw new TypeError(\'Age must be a number between 0 and 150\')\n      }\n    }\n    if (prop === \'email\') {\n      if (typeof value !== \'string\' || !value.includes(\'@\')) {\n        throw new TypeError(\'Invalid email address\')\n      }\n    }\n    return Reflect.set(target, prop, value)\n  },\n  get(target, prop) {\n    if (!(prop in target)) {\n      throw new ReferenceError(`Property \"${prop}\" does not exist`)\n    }\n    return Reflect.get(target, prop)\n  },\n}\n\nconst user = new Proxy({ name: \'\', age: 0, email: \'\' }, userValidator)\nuser.name = \'Alice\'       // OK\nuser.age = 30             // OK\n// user.age = -5           // TypeError!\n// user.email = \'invalid\'  // TypeError!\n// user.foo                // ReferenceError!\n\n// Observable proxy — auto-track property access\nfunction observable(target, onChange) {\n  return new Proxy(target, {\n    set(obj, prop, value) {\n      const old = obj[prop]\n      const result = Reflect.set(obj, prop, value)\n      if (old !== value) onChange(prop, value, old)\n      return result\n    },\n  })\n}\n\nconst state = observable({ count: 0 }, (prop, newVal) => {\n  console.log(`${prop} changed to ${newVal}`)\n})\nstate.count = 1 // logs: \'count changed to 1\'',
  followUp: 'What is `Reflect` and why is it recommended to use `Reflect` methods inside Proxy traps?',
  keyTakeaway: '`Proxy` intercepts object operations via traps, enabling validation, reactivity, and access control without modifying the target object.',
},
{
  id: 94,
  title: 'How do generators and iterators work together for lazy evaluation?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'generators',
  answer: 'Generators are functions declared with `function*` that can pause and resume execution using the `yield` keyword. When called, a generator returns an iterator that produces values on demand — each call to `next()` runs the function until the next `yield`, then suspends. This makes generators ideal for lazy evaluation, where values are computed only when requested rather than all at once. You can compose generators to build pipelines that process potentially infinite sequences without allocating memory for the entire sequence. The `yield*` syntax delegates to another generator or iterable, enabling modular composition of lazy streams.',
  codeExample: '// Infinite sequence — only computed on demand\nfunction* naturals() {\n  let n = 1\n  while (true) yield n++\n}\n\n// Lazy pipeline functions\nfunction* take(n, iterable) {\n  let count = 0\n  for (const value of iterable) {\n    if (count++ >= n) return\n    yield value\n  }\n}\n\nfunction* filter(predicate, iterable) {\n  for (const value of iterable) {\n    if (predicate(value)) yield value\n  }\n}\n\nfunction* map(fn, iterable) {\n  for (const value of iterable) {\n    yield fn(value)\n  }\n}\n\n// Compose: first 5 even squares from natural numbers\nconst result = [...take(5,\n  map(n => n * n,\n    filter(n => n % 2 === 0,\n      naturals()\n    )\n  )\n)]\nconsole.log(result) // [4, 16, 36, 64, 100]\n// Only 10 numbers were ever generated!\n\n// yield* delegation\nfunction* concat(...iterables) {\n  for (const iter of iterables) {\n    yield* iter\n  }\n}\nconsole.log([...concat([1, 2], [3, 4])]) // [1, 2, 3, 4]',
  followUp: 'How can you send values back into a generator using `next(value)` and what are the use cases?',
  keyTakeaway: 'Generators produce values lazily via `yield`, enabling memory-efficient processing of large or infinite sequences through composable pipelines.',
},
{
  id: 95,
  title: 'What is the Event Emitter pattern and how would you implement it?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'The Event Emitter pattern is a publish-subscribe mechanism where an emitter object allows listeners to register for named events and triggers those listeners when events are emitted. In Node.js, the built-in `EventEmitter` class is the backbone of streams, HTTP servers, and most core APIs. A robust implementation supports multiple listeners per event, one-time listeners that auto-remove after firing, listener removal for cleanup, and error event handling. Compared to DOM events, event emitters are simpler (no bubbling or capturing), work in any JavaScript environment, and are decoupled from the DOM hierarchy.',
  codeExample: 'class EventEmitter {\n  #events = new Map()\n\n  on(event, listener) {\n    if (!this.#events.has(event)) {\n      this.#events.set(event, [])\n    }\n    this.#events.get(event).push(listener)\n    return this\n  }\n\n  once(event, listener) {\n    const wrapper = (...args) => {\n      this.off(event, wrapper)\n      listener.apply(this, args)\n    }\n    wrapper._original = listener\n    return this.on(event, wrapper)\n  }\n\n  off(event, listener) {\n    const listeners = this.#events.get(event)\n    if (!listeners) return this\n    this.#events.set(\n      event,\n      listeners.filter(l => l !== listener && l._original !== listener)\n    )\n    return this\n  }\n\n  emit(event, ...args) {\n    const listeners = this.#events.get(event)\n    if (!listeners) return false\n    listeners.forEach(l => l.apply(this, args))\n    return true\n  }\n}\n\n// Usage\nconst bus = new EventEmitter()\nbus.on(\'data\', (msg) => console.log(\'Received:\', msg))\nbus.once(\'ready\', () => console.log(\'Ready (fires once)\'))\nbus.emit(\'ready\')  // \'Ready (fires once)\'\nbus.emit(\'ready\')  // nothing — listener was removed\nbus.emit(\'data\', \'hello\') // \'Received: hello\'',
  followUp: 'How would you add support for `async` listeners and wildcard event matching?',
  keyTakeaway: 'The Event Emitter pattern provides named event registration and emission, forming the foundation of Node.js core APIs and decoupled architectures.',
},
{
  id: 96,
  title: 'What are memory leaks in JavaScript and how do you detect them?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'Memory leaks occur when objects that are no longer needed remain referenced, preventing the garbage collector from reclaiming their memory. Common causes include forgotten event listeners, stale closures capturing large scopes, uncleared timers and intervals, detached DOM nodes still referenced in JavaScript, global variables accumulating data, and growing `Map`/`Set` collections without cleanup. You detect them using Chrome DevTools Memory tab — take heap snapshots, compare allocations over time, and look for objects whose count keeps growing. The Performance Monitor shows real-time JS heap size, and the Allocation Timeline highlights where allocations originate. `WeakMap` and `WeakSet` help prevent leaks by allowing garbage collection of their keys/values.',
  codeExample: '// LEAK: forgotten event listener\nfunction setupHandler() {\n  const hugeData = new Array(1_000_000).fill(\'x\')\n  document.addEventListener(\'click\', () => {\n    console.log(hugeData.length) // closure captures hugeData\n  })\n  // Listener is never removed — hugeData stays in memory\n}\n\n// FIX: store reference and clean up\nfunction setupHandler() {\n  const hugeData = new Array(1_000_000).fill(\'x\')\n  const handler = () => console.log(hugeData.length)\n  document.addEventListener(\'click\', handler)\n  return () => document.removeEventListener(\'click\', handler)\n}\nconst cleanup = setupHandler()\n// Later: cleanup()\n\n// LEAK: growing Map without eviction\nconst cache = new Map()\nfunction processRequest(id, data) {\n  cache.set(id, data) // cache grows forever\n}\n\n// FIX: use WeakMap (if keys are objects) or LRU cache\nconst cache = new WeakMap()\nfunction processRequest(obj, data) {\n  cache.set(obj, data) // auto-cleaned when obj is GC\'d\n}\n\n// LEAK: uncleared interval\nconst id = setInterval(() => fetch(\'/poll\'), 1000)\n// FIX: clearInterval(id) when no longer needed\n\n// Detection: compare heap snapshots\n// 1. DevTools > Memory > Take Heap Snapshot\n// 2. Perform suspect action multiple times\n// 3. Take another snapshot\n// 4. Compare — look for growing object counts',
  followUp: 'What are detached DOM nodes and how do you find them in DevTools?',
  keyTakeaway: 'Memory leaks are caused by lingering references preventing garbage collection — detect them with DevTools heap snapshots and fix with proper cleanup.',
},
{
  id: 97,
  title: 'How does the `Intl` API work for internationalization?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'intl',
  answer: 'The `Intl` namespace provides built-in constructors for language-sensitive string comparison, number formatting, date/time formatting, and more. Each constructor accepts a locale string (like `"en-US"` or `"ja-JP"`) and an options object. `Intl.NumberFormat` handles currency, percentages, units, and compact notation. `Intl.DateTimeFormat` formats dates according to locale conventions. `Intl.Collator` enables locale-aware string sorting. `Intl.RelativeTimeFormat` produces phrases like "3 days ago". `Intl.ListFormat` joins arrays into grammatically correct lists. All `Intl` formatters are stateful objects designed to be created once and reused, as construction involves expensive locale data resolution.',
  codeExample: '// Number formatting\nconst usd = new Intl.NumberFormat(\'en-US\', {\n  style: \'currency\', currency: \'USD\',\n})\nconsole.log(usd.format(1234567.89)) // \'$1,234,567.89\'\n\nconst compact = new Intl.NumberFormat(\'en\', {\n  notation: \'compact\', maximumFractionDigits: 1,\n})\nconsole.log(compact.format(1_500_000)) // \'1.5M\'\n\n// Date formatting\nconst date = new Date(\'2025-06-15T10:30:00Z\')\nconst jp = new Intl.DateTimeFormat(\'ja-JP\', {\n  dateStyle: \'long\', timeStyle: \'short\',\n})\nconsole.log(jp.format(date)) // \'2025\\u5E746\\u670815\\u65E5 19:30\'\n\n// Relative time\nconst rtf = new Intl.RelativeTimeFormat(\'en\', { numeric: \'auto\' })\nconsole.log(rtf.format(-1, \'day\'))  // \'yesterday\'\nconsole.log(rtf.format(3, \'week\'))  // \'in 3 weeks\'\n\n// List formatting\nconst list = new Intl.ListFormat(\'en\', {\n  style: \'long\', type: \'conjunction\',\n})\nconsole.log(list.format([\'JS\', \'Python\', \'Rust\']))\n// \'JS, Python, and Rust\'\n\n// Locale-aware sorting\nconst collator = new Intl.Collator(\'de\')\nconst words = [\'\\u00E4pfel\', \'Banane\', \'apfel\']\nwords.sort(collator.compare)\nconsole.log(words) // [\'\\u00E4pfel\', \'apfel\', \'Banane\']',
  followUp: 'How do you determine the user\'s preferred locale at runtime and handle fallback locales?',
  keyTakeaway: 'The `Intl` API provides built-in locale-aware formatting for numbers, dates, lists, and relative time without third-party libraries.',
},
{
  id: 98,
  title: 'What are decorators in JavaScript and what problem do they solve?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'Decorators are a stage 3 ECMAScript proposal (shipping in TC39 2023 spec and supported in TypeScript 5+) that provide a declarative syntax for modifying or augmenting classes, methods, accessors, and fields at definition time. A decorator is a function that receives context about the decorated element and can replace it, wrap it, or register initialization logic. They solve the problem of cross-cutting concerns — logging, memoization, access control, validation, and dependency injection — that would otherwise require repetitive boilerplate or runtime monkey-patching. The 2023 decorator spec is significantly different from the earlier legacy/experimental decorators used by TypeScript and Babel.',
  codeExample: '// Method decorator — logging\nfunction logged(originalMethod, context) {\n  const name = context.name\n  function replacementMethod(...args) {\n    console.log(`Calling ${name} with`, args)\n    const result = originalMethod.call(this, ...args)\n    console.log(`${name} returned`, result)\n    return result\n  }\n  return replacementMethod\n}\n\n// Auto-bind decorator\nfunction bound(originalMethod, context) {\n  const name = context.name\n  context.addInitializer(function () {\n    this[name] = this[name].bind(this)\n  })\n}\n\nclass Calculator {\n  value = 0\n\n  @logged\n  add(n) {\n    this.value += n\n    return this.value\n  }\n\n  @bound\n  @logged\n  subtract(n) {\n    this.value -= n\n    return this.value\n  }\n}\n\nconst calc = new Calculator()\ncalc.add(5)\n// logs: \'Calling add with [5]\'\n// logs: \'add returned 5\'\n\nconst { subtract } = calc\nsubtract(2) // works — bound to calc instance\n// logs: \'Calling subtract with [2]\'\n// logs: \'subtract returned 3\'',
  followUp: 'How do the new TC39 stage 3 decorators differ from the legacy TypeScript experimental decorators?',
  keyTakeaway: 'Decorators provide declarative syntax for wrapping or augmenting class elements, eliminating boilerplate for cross-cutting concerns like logging and validation.',
},
{
  id: 99,
  title: 'How do `import.meta` and import assertions work?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'modules',
  answer: '`import.meta` is a meta-property available inside ES modules that contains context about the current module. In browsers, `import.meta.url` gives the full URL of the module file, useful for resolving relative paths to assets. Node.js adds properties like `import.meta.dirname`, `import.meta.filename`, and `import.meta.resolve()`. Import attributes (formerly import assertions) use the `with` keyword to provide metadata about a module to the loader — most commonly the type. `with { type: "json" }` tells the engine to parse the file as JSON and reject it if the MIME type does not match, preventing script injection via type confusion. Import attributes also work with dynamic `import()` and CSS module imports.',
  codeExample: '// import.meta.url — resolve relative paths\nconst imageUrl = new URL(\'./logo.png\', import.meta.url)\nconsole.log(imageUrl.href)\n\n// Node.js — import.meta equivalents of __dirname\n// import.meta.dirname  (Node 21+)\n// import.meta.filename (Node 21+)\n\n// import.meta.resolve — resolve module specifiers\nconst depPath = import.meta.resolve(\'./utils.js\')\nconsole.log(depPath) // full URL to utils.js\n\n// Import attributes (with syntax)\nimport data from \'./config.json\' with { type: \'json\' }\nconsole.log(data.version)\n\nimport styles from \'./app.css\' with { type: \'css\' }\ndocument.adoptedStyleSheets.push(styles)\n\n// Dynamic import with attributes\nconst { default: config } = await import(\n  \'./settings.json\',\n  { with: { type: \'json\' } }\n)\n\n// Conditional env check\nif (import.meta.env?.DEV) {\n  console.log(\'Development mode\')\n}',
  followUp: 'Why were import assertions renamed to import attributes and what changed in the specification?',
  keyTakeaway: '`import.meta` provides module context like URLs and paths, while import attributes (`with { type }`) enforce safe type-checked module loading.',
},
{
  id: 100,
  title: 'What are the latest ECMAScript features (ES2024/ES2025)?',
  difficulty: 'hard',
  topic: 'modern-js',
  subtopic: 'patterns',
  answer: 'ES2024 introduced `Promise.withResolvers()` which returns a promise along with its `resolve` and `reject` functions, the `v` flag for RegExp with set notation and Unicode properties, `Object.groupBy()` and `Map.groupBy()` for grouping array elements, `Atomics.waitAsync()` for non-blocking shared memory, and well-formed Unicode strings via `String.prototype.isWellFormed()`. ES2025 (finalized June 2025) brings `Set` methods like `union()`, `intersection()`, `difference()`, and `symmetricDifference()`, iterator helpers such as `Iterator.prototype.map()`, `filter()`, `take()`, and `toArray()`, `RegExp.escape()`, JSON modules via import attributes, `Promise.try()`, and `Uint8Array` base64/hex methods. These features continue the trend of adding utility methods that previously required lodash or other libraries.',
  codeExample: '// ES2024 — Promise.withResolvers\nconst { promise, resolve, reject } = Promise.withResolvers()\nsetTimeout(() => resolve(\'done\'), 1000)\nawait promise // \'done\'\n\n// ES2024 — Object.groupBy\nconst people = [\n  { name: \'Alice\', age: 30 },\n  { name: \'Bob\', age: 25 },\n  { name: \'Carol\', age: 30 },\n]\nconst byAge = Object.groupBy(people, p => p.age)\n// { 25: [{name: \'Bob\', ...}], 30: [{name: \'Alice\', ...}, {name: \'Carol\', ...}] }\n\n// ES2025 — Set methods\nconst a = new Set([1, 2, 3, 4])\nconst b = new Set([3, 4, 5, 6])\na.intersection(b)       // Set {3, 4}\na.union(b)              // Set {1, 2, 3, 4, 5, 6}\na.difference(b)         // Set {1, 2}\na.symmetricDifference(b) // Set {1, 2, 5, 6}\na.isSubsetOf(b)         // false\n\n// ES2025 — Iterator helpers\nconst evens = Iterator\n  .from([1, 2, 3, 4, 5, 6, 7, 8])\n  .filter(n => n % 2 === 0)\n  .map(n => n * 10)\n  .take(3)\n  .toArray()\nconsole.log(evens) // [20, 40, 60]\n\n// ES2025 — Promise.try\nPromise.try(() => JSON.parse(input))\n  .then(data => process(data))\n  .catch(err => handleError(err))',
  followUp: 'How do `Iterator.prototype` helpers differ from array methods in terms of laziness and memory usage?',
  keyTakeaway: 'ES2024/2025 add `Promise.withResolvers`, `Object.groupBy`, `Set` methods, and iterator helpers, reducing reliance on utility libraries.',
},
]

export function filterJSQuestions(
  questions: JSInterviewQuestion[],
  difficulty: 'all' | 'easy' | 'medium' | 'hard',
  topic: string,
): JSInterviewQuestion[] {
  return questions.filter((q) => {
    if (difficulty !== 'all' && q.difficulty !== difficulty) return false
    if (topic !== 'all' && q.topic !== topic) return false
    return true
  })
}
